{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "l3CV8dRIyxJM"
   },
   "source": [
    "# NLP Project\n",
    "Urdu to Roman Urdu Transliterator\n",
    "\n",
    "Help Reference:\n",
    "https://www.tensorflow.org/addons/tutorials/networks_seq2seq_nmt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XgI4xaa7wN43"
   },
   "source": [
    "### This notebook contains the training, evaluation, and testing of the model for sentences of length <= 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d5GXHbPawpq-",
    "outputId": "2412409d-50b1-4e77-82c6-55bb5e17ac5f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting tensorflow-addons\n",
      "  Downloading tensorflow_addons-0.20.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (591 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m591.0/591.0 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow-addons) (23.1)\n",
      "Collecting typeguard<3.0.0,>=2.7\n",
      "  Downloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n",
      "Installing collected packages: typeguard, tensorflow-addons\n",
      "Successfully installed tensorflow-addons-0.20.0 typeguard-2.13.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
      "\n",
      "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
      "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
      "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
      "\n",
      "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting evaluate\n",
      "  Downloading evaluate-0.4.0-py3-none-any.whl (81 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.4/81.4 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.27.1)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from evaluate) (4.65.0)\n",
      "Collecting huggingface-hub>=0.7.0\n",
      "  Downloading huggingface_hub-0.14.1-py3-none-any.whl (224 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting responses<0.19\n",
      "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from evaluate) (1.22.4)\n",
      "Collecting multiprocess\n",
      "  Downloading multiprocess-0.70.14-py310-none-any.whl (134 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.3/134.3 kB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting xxhash\n",
      "  Downloading xxhash-3.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.5/212.5 kB\u001b[0m \u001b[31m25.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from evaluate) (23.1)\n",
      "Requirement already satisfied: fsspec[http]>=2021.05.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2023.4.0)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from evaluate) (1.5.3)\n",
      "Collecting dill\n",
      "  Downloading dill-0.3.6-py3-none-any.whl (110 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 kB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting datasets>=2.0.0\n",
      "  Downloading datasets-2.12.0-py3-none-any.whl (474 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m474.6/474.6 kB\u001b[0m \u001b[31m22.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (9.0.0)\n",
      "Collecting aiohttp\n",
      "  Downloading aiohttp-3.8.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m46.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.5.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.7.0->evaluate) (3.12.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2022.12.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (1.26.15)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2.0.12)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2022.7.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2.8.2)\n",
      "Collecting async-timeout<5.0,>=4.0.0a3\n",
      "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
      "Collecting frozenlist>=1.1.1\n",
      "  Downloading frozenlist-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (149 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.6/149.6 kB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.1.0)\n",
      "Collecting aiosignal>=1.1.2\n",
      "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Collecting multidict<7.0,>=4.5\n",
      "  Downloading multidict-6.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting yarl<2.0,>=1.0\n",
      "  Downloading yarl-1.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (268 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m30.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->evaluate) (1.16.0)\n",
      "Installing collected packages: xxhash, multidict, frozenlist, dill, async-timeout, yarl, responses, multiprocess, huggingface-hub, aiosignal, aiohttp, datasets, evaluate\n",
      "Successfully installed aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 datasets-2.12.0 dill-0.3.6 evaluate-0.4.0 frozenlist-1.3.3 huggingface-hub-0.14.1 multidict-6.0.4 multiprocess-0.70.14 responses-0.18.0 xxhash-3.2.0 yarl-1.9.2\n",
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting rouge_score\n",
      "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.4.0)\n",
      "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from rouge_score) (3.8.1)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.22.4)\n",
      "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.16.0)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (8.1.3)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (2022.10.31)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (1.2.0)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (4.65.0)\n",
      "Building wheels for collected packages: rouge_score\n",
      "  Building wheel for rouge_score (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for rouge_score: filename=rouge_score-0.1.2-py3-none-any.whl size=24954 sha256=d434bc04e8bdc6654b8a737275873ca93833e084706208ed33ff22b8715de502\n",
      "  Stored in directory: /root/.cache/pip/wheels/5f/dd/89/461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4\n",
      "Successfully built rouge_score\n",
      "Installing collected packages: rouge_score\n",
      "Successfully installed rouge_score-0.1.2\n"
     ]
    }
   ],
   "source": [
    "# imports \n",
    "import csv\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Bidirectional\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras import Input\n",
    "from tensorflow.keras.layers import Concatenate, Attention\n",
    "!pip install tensorflow-addons\n",
    "import tensorflow_addons as tfa\n",
    "from tensorflow_addons.seq2seq import BasicDecoder\n",
    "from keras.losses import SparseCategoricalCrossentropy\n",
    "import time as time\n",
    "import nltk\n",
    "from nltk.translate.bleu_score import corpus_bleu, sentence_bleu\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import random\n",
    "!pip install evaluate\n",
    "import evaluate\n",
    "!pip install rouge_score\n",
    "import numpy as np\n",
    "import heapq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Xubph_IswbCg",
    "outputId": "f74ac736-0cce-439f-f4c8-339ef66b6c51"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "# colab\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "35LlhcvSwddg"
   },
   "outputs": [],
   "source": [
    "# load datasets\n",
    "with open('/content/drive/MyDrive/NLP Project/cleaned_data/buckets_train_roman.csv', 'r') as f:\n",
    "    reader = csv.reader(f)\n",
    "    buckets_train_roman = [[[int(num) for num in sublist.split(',')] for sublist in row] for row in reader]\n",
    "\n",
    "with open('/content/drive/MyDrive/NLP Project/cleaned_data/buckets_train_urdu.csv', 'r') as f:\n",
    "    reader = csv.reader(f)\n",
    "    buckets_train_urdu = [[[int(num) for num in sublist.split(',')] for sublist in row] for row in reader]\n",
    "\n",
    "with open('/content/drive/MyDrive/NLP Project/cleaned_data/buckets_test_roman.csv', 'r') as f:\n",
    "    reader = csv.reader(f)\n",
    "    buckets_test_roman = [[[int(num) for num in sublist.split(',')] for sublist in row] for row in reader]\n",
    "\n",
    "with open('/content/drive/MyDrive/NLP Project/cleaned_data/buckets_test_urdu.csv', 'r') as f:\n",
    "    reader = csv.reader(f)\n",
    "    buckets_test_urdu = [[[int(num) for num in sublist.split(',')] for sublist in row] for row in reader]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "03IdnXXxxCLq",
    "outputId": "02f58bb7-9963-458a-b863-8dde09a16a87"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "160488"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# just printing to see if i didnt mess up anything\n",
    "len(buckets_train_roman[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "Ppw5BjZHzwrc"
   },
   "outputs": [],
   "source": [
    "# ok, i didn't mess up anything - now time to build the tensorflow dataset for the model\n",
    "\n",
    "current_index = 0 # this line is to be changed for each file\n",
    "\n",
    "# hyperparameters for the dataset\n",
    "buffer_size = 32000\n",
    "batch_size = 64\n",
    "\n",
    "# make tensorflow train and test dataset from the buckets, shuffle the train data and convert all datasets to batches of size 64 (as done in the paper)\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((buckets_train_urdu[current_index], buckets_train_roman[current_index]))\n",
    "train_dataset = train_dataset.shuffle(buffer_size).batch(batch_size, drop_remainder=True)\n",
    "\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((buckets_test_urdu[current_index], buckets_test_roman[current_index]))\n",
    "test_dataset = test_dataset.batch(batch_size, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "XqGzxUwJ11kK"
   },
   "outputs": [],
   "source": [
    "# load the tokenizers\n",
    "with open('/content/drive/MyDrive/NLP Project/tokenizer_roman.pkl', 'rb') as f:\n",
    "    tokenizer_roman_string = f.read()\n",
    "\n",
    "tokenizer_roman = pickle.loads(tokenizer_roman_string)\n",
    "\n",
    "with open('/content/drive/MyDrive/NLP Project/tokenizer_urdu.pkl', 'rb') as f:\n",
    "    tokenizer_urdu_string = f.read()\n",
    "\n",
    "tokenizer_urdu = pickle.loads(tokenizer_urdu_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "yOeKkuDD0-js"
   },
   "outputs": [],
   "source": [
    "# hyperparameters for the model\n",
    "vocab_tar_size = len(tokenizer_roman.word_index) + 1\n",
    "vocab_inp_size = len(tokenizer_urdu.word_index) + 1\n",
    "embedding_dim = 256\n",
    "units = 1024\n",
    "steps_per_epoch = 17300 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jSdxHDda5PWx"
   },
   "source": [
    "## Model Architecture:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "8_GCDDTJDSjc"
   },
   "outputs": [],
   "source": [
    "# code used from the help reference and modified a bit to fit our needs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "3i5mOeihkZKF"
   },
   "outputs": [],
   "source": [
    "# encoder\n",
    "class Encoder(Model):\n",
    "  def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz, num_layers=3):\n",
    "      super(Encoder, self).__init__()\n",
    "      self.batch_sz = batch_sz\n",
    "      self.enc_units = enc_units\n",
    "      self.embedding = Embedding(vocab_size, embedding_dim)\n",
    "      self.num_layers = num_layers\n",
    "      # bidirectional lstms, number of layers is passed from arguments\n",
    "      self.lstms = [Bidirectional(LSTM(self.enc_units, return_sequences=True, return_state=True)) for i in range(self.num_layers)]\n",
    "\n",
    "  # custom feedforward function\n",
    "  def call(self, x, hidden):\n",
    "    x = self.embedding(x)\n",
    "    states = hidden\n",
    "    new_states = []\n",
    "    # for each bi_lstm layer, pass in the initial_state from the encoder's hidden state and then get the forward activation, concatenate backward and forward activation\n",
    "    for i in range(self.num_layers):\n",
    "        forward_init_state = states[i*4:i*4+2]\n",
    "        backward_init_state = states[i*4+2:i*4+4]\n",
    "        x, forward_h, forward_c, backward_h, backward_c = self.lstms[i](x, initial_state=forward_init_state + backward_init_state)\n",
    "        h = Concatenate()([forward_h, backward_h])\n",
    "        c = Concatenate()([forward_c, backward_c])\n",
    "        new_states.extend([h, c])\n",
    "    return x, new_states\n",
    "\n",
    "  def build_initial_states(self, batch_sz):\n",
    "      return [tf.zeros((batch_sz, self.enc_units)) for _ in range(self.num_layers * 4)]  # 4 initial states (2 for each lstm layer) per layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "xvo-GHrUknzt"
   },
   "outputs": [],
   "source": [
    "# decoder\n",
    "class Decoder(Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz, num_layers):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.batch_sz = batch_sz\n",
    "        self.dec_units = dec_units\n",
    "        self.embedding = Embedding(vocab_size, embedding_dim)\n",
    "        self.num_layers = num_layers\n",
    "        # lstm layers\n",
    "        self.lstms = [LSTM(self.dec_units, return_sequences=True, return_state=True) for _ in range(self.num_layers)]\n",
    "        # output layer\n",
    "        self.fc = Dense(vocab_size)\n",
    "        # attention layer\n",
    "        self.attention = Attention()\n",
    "\n",
    "    # feedforward function \n",
    "    def call(self, x, hidden, enc_output):\n",
    "        query = tf.expand_dims(hidden[0], 1)\n",
    "        context_vector = self.attention([query, enc_output])\n",
    "\n",
    "        x = self.embedding(x)\n",
    "        x = tf.concat([context_vector, x], axis=-1)\n",
    "\n",
    "        states = hidden\n",
    "        for i in range(self.num_layers):\n",
    "            x, h, c = self.lstms[i](x, initial_state=states[i*2:i*2+2])\n",
    "            states[i*2:i*2+2] = [h, c]\n",
    "\n",
    "        output = tf.reshape(x, (-1, x.shape[2]))\n",
    "        x = self.fc(output)\n",
    "\n",
    "        return x, states\n",
    "\n",
    "    def build_initial_states(self, enc_hidden):\n",
    "        return enc_hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "uaq0XRNsDLXu"
   },
   "outputs": [],
   "source": [
    "# define Adam optimizer and use params given in paper\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ba5QAj4_GD4R"
   },
   "source": [
    "## Train and Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "pw9RCe2aDhyg"
   },
   "outputs": [],
   "source": [
    "# define the loss function - code used from help reference\n",
    "def loss_function(real, pred):\n",
    "  # multi-class classification\n",
    "  cross_entropy = SparseCategoricalCrossentropy(from_logits=True, reduction='none')\n",
    "  loss = cross_entropy(y_true=real, y_pred=pred)\n",
    "  # ignore the effect of padded 0s\n",
    "  mask = tf.logical_not(tf.math.equal(real, 0))  \n",
    "  mask = tf.cast(mask, dtype=loss.dtype)  \n",
    "  loss = mask* loss\n",
    "  loss = tf.reduce_mean(loss)\n",
    "  return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "rsEtgsr9ky0J"
   },
   "outputs": [],
   "source": [
    "# helper function to train each batch\n",
    "@tf.function\n",
    "def train_step(inp, targ, enc_hidden):\n",
    "    loss = 0\n",
    "    # pass input to encoder, get the output from the encoder and pass as input to the decoder\n",
    "    with tf.GradientTape() as tape:\n",
    "        enc_output, enc_hidden = encoder(inp, enc_hidden)\n",
    "        dec_hidden = enc_hidden\n",
    "        dec_input = tf.expand_dims([tokenizer_roman.word_index['<start>']] * batch_size, 1)\n",
    "\n",
    "        for t in range(1, targ.shape[1]):\n",
    "            predictions, dec_hidden = decoder(dec_input, dec_hidden, enc_output)\n",
    "            loss += loss_function(targ[:, t], predictions)\n",
    "            dec_input = tf.expand_dims(targ[:, t], 1)\n",
    "\n",
    "        batch_loss = (loss / int(targ.shape[1]))\n",
    "        # update training parameters (kind of like theta := theta + gradient)\n",
    "        variables = encoder.trainable_variables + decoder.trainable_variables\n",
    "        gradients = tape.gradient(loss, variables)\n",
    "        optimizer.apply_gradients(zip(gradients, variables))\n",
    "\n",
    "        return batch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kOsaNga1Echm",
    "outputId": "454396cc-ac6c-4e22-844c-523bfa62aacd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total batches: 2507\n",
      "Epoch 1 Batch 0 Loss 6.6152\n",
      "Epoch 1 Batch 1 Loss 4.2289\n",
      "Epoch 1 Batch 2 Loss 4.3505\n",
      "Epoch 1 Batch 3 Loss 3.8107\n",
      "Epoch 1 Batch 4 Loss 3.6891\n",
      "Epoch 1 Batch 5 Loss 4.0006\n",
      "Epoch 1 Batch 6 Loss 3.7158\n",
      "Epoch 1 Batch 7 Loss 4.1034\n",
      "Epoch 1 Batch 8 Loss 3.6865\n",
      "Epoch 1 Batch 9 Loss 3.8619\n",
      "Epoch 1 Batch 10 Loss 3.6880\n",
      "Epoch 1 Batch 11 Loss 3.6304\n",
      "Epoch 1 Batch 12 Loss 3.7467\n",
      "Epoch 1 Batch 13 Loss 3.5189\n",
      "Epoch 1 Batch 14 Loss 3.6300\n",
      "Epoch 1 Batch 15 Loss 3.5166\n",
      "Epoch 1 Batch 16 Loss 3.3948\n",
      "Epoch 1 Batch 17 Loss 3.8310\n",
      "Epoch 1 Batch 18 Loss 3.1884\n",
      "Epoch 1 Batch 19 Loss 3.7321\n",
      "Epoch 1 Batch 20 Loss 3.3783\n",
      "Epoch 1 Batch 21 Loss 3.4697\n",
      "Epoch 1 Batch 22 Loss 3.7293\n",
      "Epoch 1 Batch 23 Loss 3.3979\n",
      "Epoch 1 Batch 24 Loss 3.3725\n",
      "Epoch 1 Batch 25 Loss 3.3794\n",
      "Epoch 1 Loss 0.5346\n",
      "Time taken for 1 epoch 615.93 sec\n",
      "\n",
      "Epoch 2 Batch 0 Loss 3.3118\n",
      "Epoch 2 Batch 1 Loss 3.2737\n",
      "Epoch 2 Batch 2 Loss 3.3524\n",
      "Epoch 2 Batch 3 Loss 2.9972\n",
      "Epoch 2 Batch 4 Loss 3.2690\n",
      "Epoch 2 Batch 5 Loss 3.1653\n",
      "Epoch 2 Batch 6 Loss 3.2150\n",
      "Epoch 2 Batch 7 Loss 3.2763\n",
      "Epoch 2 Batch 8 Loss 3.0636\n",
      "Epoch 2 Batch 9 Loss 2.9665\n",
      "Epoch 2 Batch 10 Loss 3.1299\n",
      "Epoch 2 Batch 11 Loss 3.4287\n",
      "Epoch 2 Batch 12 Loss 3.0271\n",
      "Epoch 2 Batch 13 Loss 3.1917\n",
      "Epoch 2 Batch 14 Loss 2.8994\n",
      "Epoch 2 Batch 15 Loss 2.8760\n",
      "Epoch 2 Batch 16 Loss 3.2445\n",
      "Epoch 2 Batch 17 Loss 2.9820\n",
      "Epoch 2 Batch 18 Loss 2.7425\n",
      "Epoch 2 Batch 19 Loss 2.7931\n",
      "Epoch 2 Batch 20 Loss 2.7530\n",
      "Epoch 2 Batch 21 Loss 2.9184\n",
      "Epoch 2 Batch 22 Loss 2.8598\n",
      "Epoch 2 Batch 23 Loss 2.6433\n",
      "Epoch 2 Batch 24 Loss 2.7341\n",
      "Epoch 2 Batch 25 Loss 2.7960\n",
      "Epoch 2 Loss 0.4437\n",
      "Time taken for 1 epoch 602.88 sec\n",
      "\n",
      "Epoch 3 Batch 0 Loss 2.6095\n",
      "Epoch 3 Batch 1 Loss 2.8112\n",
      "Epoch 3 Batch 2 Loss 2.5435\n",
      "Epoch 3 Batch 3 Loss 2.3106\n",
      "Epoch 3 Batch 4 Loss 2.6488\n",
      "Epoch 3 Batch 5 Loss 2.4418\n",
      "Epoch 3 Batch 6 Loss 2.6933\n",
      "Epoch 3 Batch 7 Loss 2.4885\n",
      "Epoch 3 Batch 8 Loss 2.3150\n",
      "Epoch 3 Batch 9 Loss 2.6144\n",
      "Epoch 3 Batch 10 Loss 2.4190\n",
      "Epoch 3 Batch 11 Loss 2.4676\n",
      "Epoch 3 Batch 12 Loss 2.5089\n",
      "Epoch 3 Batch 13 Loss 2.1416\n",
      "Epoch 3 Batch 14 Loss 2.4434\n",
      "Epoch 3 Batch 15 Loss 2.1354\n",
      "Epoch 3 Batch 16 Loss 2.0738\n",
      "Epoch 3 Batch 17 Loss 2.1190\n",
      "Epoch 3 Batch 18 Loss 2.4010\n",
      "Epoch 3 Batch 19 Loss 2.0523\n",
      "Epoch 3 Batch 20 Loss 2.0832\n",
      "Epoch 3 Batch 21 Loss 1.7948\n",
      "Epoch 3 Batch 22 Loss 2.0497\n",
      "Epoch 3 Batch 23 Loss 2.1489\n",
      "Epoch 3 Batch 24 Loss 1.9527\n",
      "Epoch 3 Batch 25 Loss 1.7526\n",
      "Epoch 3 Loss 0.3347\n",
      "Time taken for 1 epoch 602.86 sec\n",
      "\n",
      "Epoch 4 Batch 0 Loss 1.6840\n",
      "Epoch 4 Batch 1 Loss 1.7555\n",
      "Epoch 4 Batch 2 Loss 1.8287\n",
      "Epoch 4 Batch 3 Loss 1.8674\n",
      "Epoch 4 Batch 4 Loss 1.6830\n",
      "Epoch 4 Batch 5 Loss 1.7197\n",
      "Epoch 4 Batch 6 Loss 1.4559\n",
      "Epoch 4 Batch 7 Loss 1.6914\n",
      "Epoch 4 Batch 8 Loss 1.4389\n",
      "Epoch 4 Batch 9 Loss 1.7604\n",
      "Epoch 4 Batch 10 Loss 1.7096\n",
      "Epoch 4 Batch 11 Loss 1.5248\n",
      "Epoch 4 Batch 12 Loss 1.4681\n",
      "Epoch 4 Batch 13 Loss 1.4035\n",
      "Epoch 4 Batch 14 Loss 1.3601\n",
      "Epoch 4 Batch 15 Loss 1.2167\n",
      "Epoch 4 Batch 16 Loss 1.4197\n",
      "Epoch 4 Batch 17 Loss 1.2765\n",
      "Epoch 4 Batch 18 Loss 1.3889\n",
      "Epoch 4 Batch 19 Loss 1.2133\n",
      "Epoch 4 Batch 20 Loss 1.3478\n",
      "Epoch 4 Batch 21 Loss 1.1230\n",
      "Epoch 4 Batch 22 Loss 1.2068\n",
      "Epoch 4 Batch 23 Loss 1.1997\n",
      "Epoch 4 Batch 24 Loss 1.0431\n",
      "Epoch 4 Batch 25 Loss 1.0726\n",
      "Epoch 4 Loss 0.2099\n",
      "Time taken for 1 epoch 603.71 sec\n",
      "\n",
      "Epoch 5 Batch 0 Loss 1.0642\n",
      "Epoch 5 Batch 1 Loss 0.9160\n",
      "Epoch 5 Batch 2 Loss 1.0433\n",
      "Epoch 5 Batch 3 Loss 0.9373\n",
      "Epoch 5 Batch 4 Loss 0.9345\n",
      "Epoch 5 Batch 5 Loss 1.0487\n",
      "Epoch 5 Batch 6 Loss 0.9083\n",
      "Epoch 5 Batch 7 Loss 1.0832\n",
      "Epoch 5 Batch 8 Loss 0.9136\n",
      "Epoch 5 Batch 9 Loss 0.8877\n",
      "Epoch 5 Batch 10 Loss 0.9073\n",
      "Epoch 5 Batch 11 Loss 0.9455\n",
      "Epoch 5 Batch 12 Loss 0.7062\n",
      "Epoch 5 Batch 13 Loss 0.8997\n",
      "Epoch 5 Batch 14 Loss 0.9698\n",
      "Epoch 5 Batch 15 Loss 0.7365\n",
      "Epoch 5 Batch 16 Loss 0.7044\n",
      "Epoch 5 Batch 17 Loss 0.7684\n",
      "Epoch 5 Batch 18 Loss 0.6856\n",
      "Epoch 5 Batch 19 Loss 0.7545\n",
      "Epoch 5 Batch 20 Loss 0.8501\n",
      "Epoch 5 Batch 21 Loss 0.8442\n",
      "Epoch 5 Batch 22 Loss 0.9047\n",
      "Epoch 5 Batch 23 Loss 0.7518\n",
      "Epoch 5 Batch 24 Loss 0.7065\n",
      "Epoch 5 Batch 25 Loss 0.6351\n",
      "Epoch 5 Loss 0.1273\n",
      "Time taken for 1 epoch 604.16 sec\n",
      "\n",
      "Epoch 6 Batch 0 Loss 0.6069\n",
      "Epoch 6 Batch 1 Loss 0.6221\n",
      "Epoch 6 Batch 2 Loss 0.7102\n",
      "Epoch 6 Batch 3 Loss 0.7761\n",
      "Epoch 6 Batch 4 Loss 0.6497\n",
      "Epoch 6 Batch 5 Loss 0.6209\n",
      "Epoch 6 Batch 6 Loss 0.6349\n",
      "Epoch 6 Batch 7 Loss 0.5334\n",
      "Epoch 6 Batch 8 Loss 0.6316\n",
      "Epoch 6 Batch 9 Loss 0.6355\n",
      "Epoch 6 Batch 10 Loss 0.4247\n",
      "Epoch 6 Batch 11 Loss 0.5836\n",
      "Epoch 6 Batch 12 Loss 0.6460\n",
      "Epoch 6 Batch 13 Loss 0.4876\n",
      "Epoch 6 Batch 14 Loss 0.4692\n",
      "Epoch 6 Batch 15 Loss 0.5098\n",
      "Epoch 6 Batch 16 Loss 0.6397\n",
      "Epoch 6 Batch 17 Loss 0.6512\n",
      "Epoch 6 Batch 18 Loss 0.5552\n",
      "Epoch 6 Batch 19 Loss 0.3841\n",
      "Epoch 6 Batch 20 Loss 0.4621\n",
      "Epoch 6 Batch 21 Loss 0.4884\n",
      "Epoch 6 Batch 22 Loss 0.4242\n",
      "Epoch 6 Batch 23 Loss 0.5441\n",
      "Epoch 6 Batch 24 Loss 0.6730\n",
      "Epoch 6 Batch 25 Loss 0.4864\n",
      "Epoch 6 Loss 0.0813\n",
      "Time taken for 1 epoch 605.22 sec\n",
      "\n",
      "Epoch 7 Batch 0 Loss 0.4540\n",
      "Epoch 7 Batch 1 Loss 0.4119\n",
      "Epoch 7 Batch 2 Loss 0.4102\n",
      "Epoch 7 Batch 3 Loss 0.4422\n",
      "Epoch 7 Batch 4 Loss 0.4305\n",
      "Epoch 7 Batch 5 Loss 0.3937\n",
      "Epoch 7 Batch 6 Loss 0.3458\n",
      "Epoch 7 Batch 7 Loss 0.3266\n",
      "Epoch 7 Batch 8 Loss 0.3098\n",
      "Epoch 7 Batch 9 Loss 0.3824\n",
      "Epoch 7 Batch 10 Loss 0.4366\n",
      "Epoch 7 Batch 11 Loss 0.3653\n",
      "Epoch 7 Batch 12 Loss 0.3598\n",
      "Epoch 7 Batch 13 Loss 0.3453\n",
      "Epoch 7 Batch 14 Loss 0.3440\n",
      "Epoch 7 Batch 15 Loss 0.2866\n",
      "Epoch 7 Batch 16 Loss 0.3191\n",
      "Epoch 7 Batch 17 Loss 0.4196\n",
      "Epoch 7 Batch 18 Loss 0.3069\n",
      "Epoch 7 Batch 19 Loss 0.3381\n",
      "Epoch 7 Batch 20 Loss 0.2418\n",
      "Epoch 7 Batch 21 Loss 0.3327\n",
      "Epoch 7 Batch 22 Loss 0.3855\n",
      "Epoch 7 Batch 23 Loss 0.3326\n",
      "Epoch 7 Batch 24 Loss 0.2661\n",
      "Epoch 7 Batch 25 Loss 0.2742\n",
      "Epoch 7 Loss 0.0526\n",
      "Time taken for 1 epoch 603.87 sec\n",
      "\n",
      "Epoch 8 Batch 0 Loss 0.2750\n",
      "Epoch 8 Batch 1 Loss 0.2555\n",
      "Epoch 8 Batch 2 Loss 0.2572\n",
      "Epoch 8 Batch 3 Loss 0.1492\n",
      "Epoch 8 Batch 4 Loss 0.2911\n",
      "Epoch 8 Batch 5 Loss 0.2098\n",
      "Epoch 8 Batch 6 Loss 0.2941\n",
      "Epoch 8 Batch 7 Loss 0.2775\n",
      "Epoch 8 Batch 8 Loss 0.2035\n",
      "Epoch 8 Batch 9 Loss 0.1618\n",
      "Epoch 8 Batch 10 Loss 0.1816\n",
      "Epoch 8 Batch 11 Loss 0.2142\n",
      "Epoch 8 Batch 12 Loss 0.1350\n",
      "Epoch 8 Batch 13 Loss 0.2249\n",
      "Epoch 8 Batch 14 Loss 0.3374\n",
      "Epoch 8 Batch 15 Loss 0.2553\n",
      "Epoch 8 Batch 16 Loss 0.2391\n",
      "Epoch 8 Batch 17 Loss 0.2621\n",
      "Epoch 8 Batch 18 Loss 0.2087\n",
      "Epoch 8 Batch 19 Loss 0.1877\n",
      "Epoch 8 Batch 20 Loss 0.2517\n",
      "Epoch 8 Batch 21 Loss 0.1781\n",
      "Epoch 8 Batch 22 Loss 0.1950\n",
      "Epoch 8 Batch 23 Loss 0.2523\n",
      "Epoch 8 Batch 24 Loss 0.1917\n",
      "Epoch 8 Batch 25 Loss 0.2325\n",
      "Epoch 8 Loss 0.0339\n",
      "Time taken for 1 epoch 604.18 sec\n",
      "\n",
      "Epoch 9 Batch 0 Loss 0.1394\n",
      "Epoch 9 Batch 1 Loss 0.1378\n",
      "Epoch 9 Batch 2 Loss 0.1337\n",
      "Epoch 9 Batch 3 Loss 0.1791\n",
      "Epoch 9 Batch 4 Loss 0.1874\n",
      "Epoch 9 Batch 5 Loss 0.1621\n",
      "Epoch 9 Batch 6 Loss 0.1593\n",
      "Epoch 9 Batch 7 Loss 0.1427\n",
      "Epoch 9 Batch 8 Loss 0.3173\n",
      "Epoch 9 Batch 9 Loss 0.1724\n",
      "Epoch 9 Batch 10 Loss 0.1513\n",
      "Epoch 9 Batch 11 Loss 0.1478\n",
      "Epoch 9 Batch 12 Loss 0.1330\n",
      "Epoch 9 Batch 13 Loss 0.1281\n",
      "Epoch 9 Batch 14 Loss 0.1067\n",
      "Epoch 9 Batch 15 Loss 0.1326\n",
      "Epoch 9 Batch 16 Loss 0.1820\n",
      "Epoch 9 Batch 17 Loss 0.1704\n",
      "Epoch 9 Batch 18 Loss 0.1218\n",
      "Epoch 9 Batch 19 Loss 0.1359\n",
      "Epoch 9 Batch 20 Loss 0.1053\n",
      "Epoch 9 Batch 21 Loss 0.1497\n",
      "Epoch 9 Batch 22 Loss 0.2008\n",
      "Epoch 9 Batch 23 Loss 0.2114\n",
      "Epoch 9 Batch 24 Loss 0.1315\n",
      "Epoch 9 Batch 25 Loss 0.1531\n",
      "Epoch 9 Loss 0.0221\n",
      "Time taken for 1 epoch 602.58 sec\n",
      "\n",
      "Epoch 10 Batch 0 Loss 0.1145\n",
      "Epoch 10 Batch 1 Loss 0.1060\n",
      "Epoch 10 Batch 2 Loss 0.0858\n",
      "Epoch 10 Batch 3 Loss 0.0920\n",
      "Epoch 10 Batch 4 Loss 0.1019\n",
      "Epoch 10 Batch 5 Loss 0.0956\n",
      "Epoch 10 Batch 6 Loss 0.1119\n",
      "Epoch 10 Batch 7 Loss 0.1027\n",
      "Epoch 10 Batch 8 Loss 0.1021\n",
      "Epoch 10 Batch 9 Loss 0.0714\n",
      "Epoch 10 Batch 10 Loss 0.0951\n",
      "Epoch 10 Batch 11 Loss 0.1020\n",
      "Epoch 10 Batch 12 Loss 0.2405\n",
      "Epoch 10 Batch 13 Loss 0.0599\n",
      "Epoch 10 Batch 14 Loss 0.2285\n",
      "Epoch 10 Batch 15 Loss 0.0661\n",
      "Epoch 10 Batch 16 Loss 0.0763\n",
      "Epoch 10 Batch 17 Loss 0.0814\n",
      "Epoch 10 Batch 18 Loss 0.1465\n",
      "Epoch 10 Batch 19 Loss 0.0934\n",
      "Epoch 10 Batch 20 Loss 0.0844\n",
      "Epoch 10 Batch 21 Loss 0.0701\n",
      "Epoch 10 Batch 22 Loss 0.1029\n",
      "Epoch 10 Batch 23 Loss 0.0664\n",
      "Epoch 10 Batch 24 Loss 0.0712\n",
      "Epoch 10 Batch 25 Loss 0.1007\n",
      "Epoch 10 Loss 0.0138\n",
      "Time taken for 1 epoch 603.02 sec\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# main training loop - code modified from help reference\n",
    "import time as time\n",
    "\n",
    "EPOCHS = 10\n",
    "train_loss = []\n",
    "num_layers = 1\n",
    "\n",
    "encoder = Encoder(vocab_inp_size, embedding_dim, units, batch_size, num_layers)\n",
    "decoder = Decoder(vocab_tar_size, embedding_dim, units*2, batch_size, num_layers)\n",
    "print('total batches:', len(train_dataset))\n",
    "for epoch in range(EPOCHS):\n",
    "    start = time.time()\n",
    "\n",
    "    enc_hidden = encoder.build_initial_states(batch_size)\n",
    "    total_loss = 0\n",
    "\n",
    "    for (batch, (inp, targ)) in enumerate(train_dataset.take(steps_per_epoch)):\n",
    "        batch_loss = train_step(inp, targ, enc_hidden)\n",
    "        train_loss.append(batch_loss)\n",
    "        total_loss += batch_loss\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            print(f'Epoch {epoch+1} Batch {batch // 100} Loss {batch_loss.numpy():.4f}')\n",
    "\n",
    "    print(f'Epoch {epoch+1} Loss {total_loss/steps_per_epoch:.4f}')\n",
    "    print(f'Time taken for 1 epoch {time.time()-start:.2f} sec\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "id": "987tAUP4_2o4"
   },
   "outputs": [],
   "source": [
    "# beam search:\n",
    "import math \n",
    "\n",
    "def predict_beam(test_bucket):\n",
    "  output = []\n",
    "  # iterate through each example\n",
    "  for i, (roman_sentence, urdu_sentence) in enumerate(test_bucket):\n",
    "    # print(i, \"examples done,\", len(test_bucket) - i, \"remain\")\n",
    "    # convert the sentence to its numeric sequence to give to the model\n",
    "    urdu_sequence = [tokenizer_urdu.word_index[i] if i in tokenizer_urdu.word_index else tokenizer_urdu.word_index['<OOV>'] for i in urdu_sentence.split(' ')]\n",
    "    urdu_sequence = pad_sequences([urdu_sequence], padding='post')\n",
    "    # convert the sequence to a tensor\n",
    "    urdu_sequence = tf.convert_to_tensor(urdu_sequence)\n",
    "    inference_batch_size = urdu_sequence.shape[0]\n",
    "    # call the encoder\n",
    "    enc_start_state = [tf.zeros((inference_batch_size, units)) for _ in range(num_layers * 4)]\n",
    "    enc_out, enc_hidden = encoder(urdu_sequence, enc_start_state)\n",
    "    # create input for decoder\n",
    "    dec_hidden = enc_hidden\n",
    "    dec_input = tf.expand_dims([tokenizer_roman.word_index['<start>']] * inference_batch_size, 1)\n",
    "    max_len_output = 10\n",
    "    # get the input sequence for the decoder\n",
    "    input_sequence = dec_input.numpy()\n",
    "    # initialize the candidates from beam search, each row is of type: (candidate_sequence, log_probability)\n",
    "    beam_candidates = [[input_sequence, 0.0]]\n",
    "    beam_width = 5\n",
    "    for t in range(max_len_output):\n",
    "      # store the next candidates\n",
    "      next_candidates = []\n",
    "      # for each sequence in the current list of candidates\n",
    "      for seq, score in beam_candidates:\n",
    "        seq = tf.convert_to_tensor(seq)\n",
    "        dec_input = tf.expand_dims(tf.convert_to_tensor([seq.numpy()[0][-1]]) if len(seq) > 0 else tokenizer_roman.word_index['<start>'], 0)\n",
    "        # get the predictions for each token from the decoder for this sequence\n",
    "        predictions, dec_hidden = decoder(dec_input, dec_hidden, enc_out)\n",
    "        min_len = len(roman_sentence.split(' '))\n",
    "        # punish printing <end> before len(roman_sentence)\n",
    "        if t < min_len:\n",
    "          end_token_inx = tokenizer_roman.word_index['<end>']\n",
    "          mask = tf.one_hot(end_token_inx, predictions.shape[-1], dtype=tf.float32)\n",
    "          predictions = tf.where(mask == 1, tf.ones_like(predictions) * -float('inf'), predictions)\n",
    "        # store the top k most probable ones - beam search\n",
    "        top_k_preds = tf.math.top_k(predictions[0], k=beam_width)\n",
    "        for current_beam in range(beam_width):\n",
    "          predicted_index = top_k_preds.indices[current_beam].numpy()\n",
    "          candidate_sequence = tf.concat([seq, tf.convert_to_tensor([[predicted_index]])], axis=1)\n",
    "          candidate_score = score - math.log(top_k_preds.values[current_beam])\n",
    "          next_candidates.append([candidate_sequence, candidate_score])\n",
    "        \n",
    "      # sort candidates by their score\n",
    "      sorted_candidates = sorted(next_candidates, key=lambda tup: tup[1])\n",
    "      # get the top beam_width candidates\n",
    "      beam_candidates = sorted_candidates[:beam_width]\n",
    "      # exit loop if all candidates have generated <end> token\n",
    "      # if all([tokenizer_roman.index_word[c[0].numpy()[0][-1]] == '<end>' for c in beam_candidates]):\n",
    "      #   break\n",
    "\n",
    "    # best candidate\n",
    "    best_sequence = beam_candidates[0][0]\n",
    "    result = ' '.join([tokenizer_roman.index_word[idx] for idx in best_sequence.numpy()[0]])\n",
    "    output.append((roman_sentence.replace('<start>', '').replace('<end>', '').strip(), result.replace('<start>', '').replace('<end>', '').strip()))\n",
    "  return output\n",
    "\n",
    "# greedy search:\n",
    "def predict_greedy(test_dataset):\n",
    "  preds_bucket = []\n",
    "  # for each example in the test set\n",
    "  for i, tup in enumerate(test_dataset):\n",
    "    # call the evaluate_sentence func on the urdu text's batch\n",
    "    result = evaluate_sentence(tup[1]).replace(\"<start>\", \"\").replace(\"<end>\", \"\").strip()\n",
    "    expected = tup[0].replace(\"<start>\", \"\").replace(\"<end>\", \"\").strip()\n",
    "    preds_bucket.append((expected, result))\n",
    "    if i % 100 == 0:\n",
    "      print(i, \"test examples done,\", len(test_dataset) - i, \"left.\")\n",
    "  print('all done!')\n",
    "  return preds_bucket\n",
    "\n",
    "def evaluate_sentence(sentence):\n",
    "    inputs = [tokenizer_urdu.word_index[i] if i in tokenizer_urdu.word_index else tokenizer_urdu.word_index['<OOV>'] for i in sentence.split(' ')]\n",
    "    inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs], padding='post')\n",
    "    inputs = tf.convert_to_tensor(inputs)\n",
    "    inference_batch_size = inputs.shape[0]\n",
    "    result = '<start>'\n",
    "    enc_start_state = [tf.zeros((inference_batch_size, units)) for _ in range(num_layers * 4)] \n",
    "    enc_out, enc_hidden = encoder(inputs, enc_start_state)\n",
    "    \n",
    "    dec_hidden = enc_hidden\n",
    "    dec_input = tf.expand_dims([tokenizer_roman.word_index['<start>']] * inference_batch_size, 1)\n",
    "    \n",
    "    for t in range(40):\n",
    "\n",
    "      predictions, dec_hidden = decoder(dec_input, dec_hidden, enc_out) \n",
    "        \n",
    "      # just use argmax to get the token with the highest probability\n",
    "      predicted_id = tf.argmax(predictions, axis=-1).numpy()[0]\n",
    "        \n",
    "      result += tokenizer_roman.index_word[predicted_id] + ' '\n",
    "        \n",
    "      if tokenizer_roman.index_word[predicted_id] == '<end>':\n",
    "          return result.strip()\n",
    "        \n",
    "      # pass the predicted token as the next input to the decoder\n",
    "      dec_input = tf.expand_dims([predicted_id] * inference_batch_size, 1)\n",
    "      \n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "FJLg1SkbFkE3"
   },
   "outputs": [],
   "source": [
    "# helper function to calculate bleu score\n",
    "def calculate_bleu_score(preds):\n",
    "  # Split the dataset into expected translations and predicted translations.\n",
    "  expected = [pair[0] for pair in preds]\n",
    "  predicted = [pair[1] for pair in preds]\n",
    "\n",
    "  # # Calculate the BLEU score for each sentence and average BLEU score for all test sentences\n",
    "  bleu_scores = [sentence_bleu([ref.split()], pred.split()) for ref, pred in zip(predicted, expected)]\n",
    "  avg_bleu_score = corpus_bleu([[ref.split()] for ref in expected], [pred.split() for pred in predicted])\n",
    "\n",
    "  return avg_bleu_score * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "-E4lf5NWG3J2"
   },
   "outputs": [],
   "source": [
    "def loss_graph(train_loss):\n",
    "  train_steps = list(range(len(train_loss)))\n",
    "  # Create the figure and axis objects\n",
    "  fig, ax = plt.subplots()\n",
    "  # Plot the data\n",
    "  ax.plot(train_steps, train_loss, color='blue')\n",
    "  # Set the title and axis labels\n",
    "  ax.set_title('Training Loss')\n",
    "  ax.set_xlabel('Training Steps')\n",
    "  ax.set_ylabel('Training Loss')\n",
    "  # Show the plot\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "id": "NW6s5tcVIMGJ",
    "outputId": "c4c890c7-ca53-46e5-f9cd-b8834194a666"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the training loss graph\n",
    "loss_graph(train_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "fGIVWIs7GnHj"
   },
   "outputs": [],
   "source": [
    "# load the test data\n",
    "import pickle\n",
    "\n",
    "with open('/content/drive/MyDrive/NLP Project/test_buckets.pickle', 'rb') as f:\n",
    "    test_buckets = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mA11LwNiGM31",
    "outputId": "fb7f20ca-f5ea-4fb0-e74c-029ae8ab5aeb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('shab bakhair', 'walay hain yn they'),\n",
       " ('mehfhil mein aap ka kher muqaddam hai',\n",
       "  'mehfhil mein hai 1 hon sarah hain pehlay !'),\n",
       " ('aur khawab khar gosh', 'aur misl bhiya hum yn hum'),\n",
       " ('aglay sabaq mein kitni der hai ustaad mohtaram',\n",
       "  'aglay sabaq mohtaram sarah hai jawab hai pakistan hai ki'),\n",
       " ('Tafseer muki', 'younis . mujhe 2007'),\n",
       " ('bees tareekh hai jummay al ki', 'bees qist ke hai 1 hai 1 hai'),\n",
       " ('aur aap ko duayen den ge', 'aur aap gi sarah hain hum yn aap'),\n",
       " ('ki rahi meri aaj ki ki', 'ki pata azam hon ki ja kyun den'),\n",
       " ('mujhe jawab ka intzaar rahay ga : )',\n",
       "  'mujhe ik ) yeh hai ki hai jawab hai jawab'),\n",
       " ('ki do nai kara den', 'ki gaari hain ki hain ki hain'),\n",
       " ('jo munasib ke Wilayat ke hain makhsoos',\n",
       "  'jo munasib ton ki hai ke hai din hai'),\n",
       " ('itnay achay ke mein ( jo Shakir )',\n",
       "  'itnay achay shakir hum hain sab hain kehte hain sab'),\n",
       " ('tig : shairi , ghazal , nasir Hussain',\n",
       "  'tig : nasir kitaab 1 hai 1 hai 1 hai'),\n",
       " ('khud ko ko', 'ko pohanchi usay zila hum'),\n",
       " ('baghaawat mujh se hain narmi', 'kab dhoond yn taq samajh baghaawat hain'),\n",
       " ('khud kash dhamakay aur hamari zimma ke',\n",
       "  'khud kash ke they hum abad they hum hotay'),\n",
       " ('habsha ke nasari ki tareef', 'chorney ke hai quran hain hum hain'),\n",
       " ('aap pehlay hi daakhil haalat mein hain',\n",
       "  'aap pehlay hain ke hain pehlay hain hum hain'),\n",
       " ('guftagu mein ajab fasahat bhi', 'mein bhi yn ke hain ke hain'),\n",
       " ('bohat achay janab ki hui na baat',\n",
       "  'bohat achay baat yn hai ki hai mujhe ho'),\n",
       " ('Anees Al bhai ki hoshyari', 'anees shafi hai 1 ho zila zila'),\n",
       " ('Amaar Ibn zia , September 15 , 2007', 'amaar ibn 5 , 2007 , 2007 , 2007 ,'),\n",
       " ('mein baithta to mra hamsafar par jata',\n",
       "  'par to jata hai pakistan hon ki dekha hai'),\n",
       " ('muqaddar ki liye dahai Hussain', 'muqaddar ki usool , ga - aat'),\n",
       " ('kyun kya pasand nahi aayi meri tajweez',\n",
       "  'kyun kya fehmi len zila kyun hai hum hai'),\n",
       " ('liye naam hum kya hai', 'ataa kya islam ! sarah hain hum'),\n",
       " ('khush aamdeed is dhaagay par', 'khush kahi . ki yeh urdu mazeed'),\n",
       " ('saalgirah mubarak .', '! karni ! yn ho'),\n",
       " ('is ko mein', 'ki jaakar mujhe jawab hai'),\n",
       " ('batain baghaawat reh gaye aap .', 'batain kyun . usay hain _ hin hain'),\n",
       " ('arrey ne bhai Osama Osama !', 'arrey ne ) sarah ) sarah ! -'),\n",
       " ('kasak ban ke laga', 'p pa hain - hakoomat they'),\n",
       " ('hai karne ke liye duayen', 'hai karne yn hai yn - hakoomat'),\n",
       " ('salam Iqbal', 'aur soorat hai iqbal'),\n",
       " ('bakol Muhib aloy', 'ke ameeen lala amjad amjad'),\n",
       " ('qaisrani , May 21 , 2012', 'qaisrani , 2006 , 2007 , 2009 ,'),\n",
       " ('Peshawar ke mein par khudkush fazai',\n",
       "  'peshawar ke halakatain yeh usay hain sarah they'),\n",
       " ('mein faqat aik hi tasweer kahan taq daikhon',\n",
       "  'har aik daikhon hai pakistan hai jawab hai pakistan hai'),\n",
       " ('az bahadur Shah Zafar', 'master qaazi ! ali ) khan'),\n",
       " ('hajj ka dainay nazar kya hai nabeel ki',\n",
       "  'hajj ka nabeel hai quran hai 1 hai 1 hai'),\n",
       " ('ki yahan aakar khud kashi nah karle kahin',\n",
       "  'ki yahan shud mujhe gaon usay yeh yeh yeh yeh'),\n",
       " ('saalgirah bohat mubarak ho Shamshad sahib !',\n",
       "  'saalgirah bohat tohfa hai thisishypenhere ho rahay ! thisishypenhere'),\n",
       " ('zainab , January 9 , 2009', 'osama , 2007 , 2007 , 2009 ,'),\n",
       " ('phir isi be abbu pay martay hain',\n",
       "  'phir isi hain hamaray dekhen din hai quran hai'),\n",
       " ('mustafa Hussain ( 1 )', 'zameer 1 hain 1 hai 1 hai'),\n",
       " ('hinduo ki tehreek se alehadgi', 'jald aan hai ki hain sarah hain'),\n",
       " ('qaisrani , itwaar boqt 2 : 36 shaam',\n",
       "  'qaisrani , 35 shaam mujhe 7 , 2007 , 2009'),\n",
       " ('ke museebat pari tamanna par', 'ke ada hai sarah they ki hai'),\n",
       " ('balouch qiyam yonayitd ho', 'mk ho thisishypenhere azam ) zila'),\n",
       " ('doosri ghalat bayani', 'ki dhamki hai jawab hai'),\n",
       " ('kaisay be rukhi se hum', 'yaqeenan hum yn yn they yn they'),\n",
       " ('Mohammad hazrat Akhtar', 'mohammad rafi ! 1 hai'),\n",
       " ('achanak nazar ka parna aur napasandeedah nazar',\n",
       "  'achanak nazar barish they yn they yn kar ho'),\n",
       " ('janshin mera khandan se rahay', 'juz se hain ki yn hai ki'),\n",
       " ('Kashmir banay ga Pakistan', 'ain pakistan hai 5 hai dekha'),\n",
       " ('typing ka pehla zeena', 'share - aat ) ki )'),\n",
       " ('setaaray un ke naazuk paiir', 'setaaray un they hum hain am they'),\n",
       " ('khud ko zaat mein ik karwan hon',\n",
       "  'khud ko lagta ke hain apne hai hum they'),\n",
       " ('hum aisay bhoolnay walay nahi they', 'hum aisay hain hum hum hain hum hum'),\n",
       " ('uday wall soonahre', '- e - hakoomat hai'),\n",
       " ('Itra ke chal di kahan', 'dar kahan sanam hai abad hain -'),\n",
       " ('jee ki mazaar shareef hi hai', 'jee yeh naan - hin hain lala )'),\n",
       " ('husn aloy , July 31 , 2008', 'husn aloy 2008 , 2009 , 2007 , 2007'),\n",
       " ('Surriya ki guria', '- nasiyaat hai ki waqt'),\n",
       " ('bhala kya ki roshan kere ga apne ko',\n",
       "  'bhala kya zamane hai they usay ho kyun ho they'),\n",
       " ('reaya abhi taq', 'ki nahi yn mujhe yn'),\n",
       " ('baba aisay nahi kehte !', 'baba hum sanam they they batao they'),\n",
       " ('lekin aapko sa sa kharcha karna hoga',\n",
       "  'lekin aapko hoga rukh hai lala zila zila zila'),\n",
       " ('hai chaar din ki hamari ne', 'hai chaar sada hon 2 hon 3 they'),\n",
       " ('Saima Shah , feb 16 , 2012', 'saima shah 2012 , 2006 , 2006 , 2007'),\n",
       " ('safha 44 se safha 58 taq', ', 58 . 4 . 4 . 4'),\n",
       " ('yahan bhi barish horahee hai', 'yahan to din dekhen yeh usay hai'),\n",
       " ('naqsh : tasweer', 'qayamat talab hai ki hai'),\n",
       " ('Ali baba , April 2 , 2006', 'saleem , 2006 ke 2007 , 2007 , 2007'),\n",
       " ('mustaqil nahi hota', 'wahan aaya . mujhe yn'),\n",
       " ('sab se kam over mein khatam 10', 'sab se 10 hain , hain 3 len 3'),\n",
       " ('aish milta hai khaas logon ko', 'aish hota sanam hai abad hon abad hai'),\n",
       " ('4 deal astin janoobi Africa 663', '4 102 yn , hain 3 hon 2'),\n",
       " ('( Danish )', '( 53 hai 1 hai'),\n",
       " ('lehed mein peda honay walay bachay', 'lehed mein hain abad hon abad hon 4'),\n",
       " ('mit nahi sakta kabhi mard musalman ke hai',\n",
       "  'mit nahi islam hai di hai kabhi ja nahi ho'),\n",
       " ('bohat nazar Mirza sahib', 'barri hai yn hai yn hai'),\n",
       " ('lekin ki zurori to nahi na janab',\n",
       "  'lekin ki janab gaon hai ne hai din hai'),\n",
       " ('aaj kya khota hai', 'mera to gaon hai ne hai'),\n",
       " ('jata hai do hazaar tera bhi', 'jata hai mein hai meter hon ki hai'),\n",
       " ('aap sunaaiye aap kaisi hain', 'lijiye hain - hakoomat yn yn hai'),\n",
       " ('to biwi safha 82', 'sa 39 hai mujhe 2009 zila'),\n",
       " ('islami mumalik ki difai dil', 'islami mumalik shayar len 1 hain ki'),\n",
       " ('muki , July 8 , 2011', 'muki , 2007 , 2009 , 2009 ,'),\n",
       " ('sipahi true aunti', 'ke 2007 hai usay gi'),\n",
       " ('raat ki kalak siyasat par thop di',\n",
       "  'raat ki di shaam mujhe raat hai raat yaad'),\n",
       " ('mehfhil par doosri saalgirah mubarak ho qaisrani',\n",
       "  'sarah mubarak islam hai ki hai islam ki hai'),\n",
       " ('hamari ki to ab yahin munasib lagti hai',\n",
       "  'hamari ki lagti ke hai din hai yeh ne hai'),\n",
       " ('jo apne aap mein raakh ka samandar hain',\n",
       "  'jo aapne hain hum hain apne hain ke hain apne'),\n",
       " ('Shahid afridi bay Zahir 10 14 1 0', 'shahid afridi 1 ! 1 . 1 , 2007 ,'),\n",
       " ('acha acha socha karen baba', 'acha karen _ hin hon usay hon'),\n",
       " ('aap ke liye aik shair', 'lijiye shair k sarah yn mazeed hain'),\n",
       " ('iqtabas kaisay karna he', 'matloob baat kehte they yn they'),\n",
       " ('aks ain , September 5 , 2009', 'aks ain 45 , 2009 mujhe 5 , 2009'),\n",
       " ('mushawarat ke tareeq mein', 'bil masjid hain sarah hain ki')]"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate the prediction\n",
    "preds_bucket_beam = predict_beam(test_buckets[current_index][0:100])\n",
    "preds_bucket_beam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gtqom0c1xd7I",
    "outputId": "af88adeb-c3bf-4330-bf23-73da64c6b2a7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU SCORE OF BUCKET SIZE 10: 8.793816932193118e-77\n",
      "ROUGE SCORE OF BUCKET SIZE 10: {'rouge1': 0.2448761377511377, 'rouge2': 0.062223748473748494, 'rougeL': 0.23800330225330224, 'rougeLsum': 0.23775333000332993}\n"
     ]
    }
   ],
   "source": [
    "# quantitaive analysis - bleu score of model, rouge score\n",
    "print('beam search')\n",
    "bleu_score = calculate_bleu_score(preds_bucket_beam)\n",
    "rouge = evaluate.load('rouge')\n",
    "expected = [pair[0] for pair in preds_bucket_beam]\n",
    "predicted = [pair[1] for pair in preds_bucket_beam]\n",
    "rouge_score = rouge.compute(predictions=predicted, references=expected)\n",
    "print(\"BLEU SCORE OF BUCKET SIZE 10:\", bleu_score)\n",
    "print(\"ROUGE SCORE OF BUCKET SIZE 10:\", rouge_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QlV0tSzL6yJw",
    "outputId": "a79cd9d5-4e97-478c-c079-4e928a4de94c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 test examples done, 100 left.\n",
      "all done!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('shab bakhair', 'ke gala'),\n",
       " ('mehfhil mein aap ka kher muqaddam hai',\n",
       "  'mehfhil mein aap ka kher muqaddam hai'),\n",
       " ('aur khawab khar gosh', 'ke gumaan tishna shikan'),\n",
       " ('aglay sabaq mein kitni der hai ustaad mohtaram',\n",
       "  'aglay sabaq mein kitni der hai ustaad mohtaram'),\n",
       " ('Tafseer muki', ', 2008'),\n",
       " ('bees tareekh hai jummay al ki', 'bees tareekh hai jummay al ki ki'),\n",
       " ('aur aap ko duayen den ge', 'aur aap ko duayen den ge'),\n",
       " ('ki rahi meri aaj ki ki', 'ki rahi hamein aaj ki ki'),\n",
       " ('mujhe jawab ka intzaar rahay ga : )',\n",
       "  'mujhe jawab ka intzaar rahay ga : )'),\n",
       " ('ki do nai kara den', 'ki gaari shuda mulaqaat den'),\n",
       " ('jo munasib ke Wilayat ke hain makhsoos',\n",
       "  'jo munasib ke masawaat ke hain makhsoos'),\n",
       " ('itnay achay ke mein ( jo Shakir )', 'itnay achay ke mein ( jo shakir )'),\n",
       " ('tig : shairi , ghazal , nasir Hussain',\n",
       "  'tig : shairi , ghazal , nasir hussain'),\n",
       " ('khud ko ko', 'ko suna'),\n",
       " ('baghaawat mujh se hain narmi', 'kab haar paich hain narmi'),\n",
       " ('khud kash dhamakay aur hamari zimma ke',\n",
       "  'khud kash dhamakay aur hamari zimma ke'),\n",
       " ('habsha ke nasari ki tareef', 'chorney ke khusoosi ki tareef'),\n",
       " ('aap pehlay hi daakhil haalat mein hain',\n",
       "  'aap pehlay hi 58 haalat mein hain'),\n",
       " ('guftagu mein ajab fasahat bhi', 'par aisi himayat , bhi'),\n",
       " ('bohat achay janab ki hui na baat', 'bohat achay janab ki hui na baat'),\n",
       " ('Anees Al bhai ki hoshyari', 'anees al alkrim ki arshadat'),\n",
       " ('Amaar Ibn zia , September 15 , 2007',\n",
       "  'amaar ibn zia , september 15 , 2007'),\n",
       " ('mein baithta to mra hamsafar par jata',\n",
       "  'mein baithta to mra hamsafar par jata'),\n",
       " ('muqaddar ki liye dahai Hussain', 'muqaddar ki bakri dahai hussain'),\n",
       " ('kyun kya pasand nahi aayi meri tajweez',\n",
       "  'kyun kya pasand nahi aayi meri tajweez'),\n",
       " ('liye naam hum kya hai', 'liye sara kya kya hai'),\n",
       " ('khush aamdeed is dhaagay par', 'khush dua is dhaagay par'),\n",
       " ('saalgirah mubarak .', '! gussa taajjub'),\n",
       " ('is ko mein', 'ki garmi'),\n",
       " ('batain baghaawat reh gaye aap .', 'batain baghaawat reh gaye aap .'),\n",
       " ('arrey ne bhai Osama Osama !', 'arrey ne bhai osama osama !'),\n",
       " ('kasak ban ke laga', 'p - ani se railay hain'),\n",
       " ('hai karne ke liye duayen', 'hai karne ke liye duayen'),\n",
       " ('salam Iqbal', 'aur aik'),\n",
       " ('bakol Muhib aloy', 'ae raazi'),\n",
       " ('qaisrani , May 21 , 2012', 'qaisrani , may 21 , 2012'),\n",
       " ('Peshawar ke mein par khudkush fazai', 'peshawar ke mein par fouji fazai'),\n",
       " ('mein faqat aik hi tasweer kahan taq daikhon',\n",
       "  'mein faqat aik hi tasweer kahan taq daikhon'),\n",
       " ('az bahadur Shah Zafar', 'az ilaaha aleh khan'),\n",
       " ('hajj ka dainay nazar kya hai nabeel ki',\n",
       "  'hajj ka paishgi nazar kya hai nabeel ki'),\n",
       " ('ki yahan aakar khud kashi nah karle kahin',\n",
       "  'ki yahan aakar khud kashi nah karle kahin'),\n",
       " ('saalgirah bohat mubarak ho Shamshad sahib !',\n",
       "  'saalgirah bohat mubarak ho shamshad sahib !'),\n",
       " ('zainab , January 9 , 2009', 'zainab , january 9 , 2009'),\n",
       " ('phir isi be abbu pay martay hain', 'phir isi be abbu pay martay hain'),\n",
       " ('mustafa Hussain ( 1 )', 'raahat hussain 56 1 )'),\n",
       " ('hinduo ki tehreek se alehadgi', 'ke insani un se alehadgi'),\n",
       " ('qaisrani , itwaar boqt 2 : 36 shaam',\n",
       "  'qaisrani , itwaar boqt 2 : 36 shaam'),\n",
       " ('ke museebat pari tamanna par', 'ke ada saya sakht par'),\n",
       " ('balouch qiyam yonayitd ho', 'e - ha ki ho jaye'),\n",
       " ('doosri ghalat bayani', 'ki dhamki'),\n",
       " ('kaisay be rukhi se hum', 'kaisay apna 13 se hum'),\n",
       " ('Mohammad hazrat Akhtar', 'mohammad rafi fardaa'),\n",
       " ('achanak nazar ka parna aur napasandeedah nazar',\n",
       "  'achanak nazar ka merg aur toseefi nazar'),\n",
       " ('janshin mera khandan se rahay', 'nng kya fi se rahay'),\n",
       " ('Kashmir banay ga Pakistan', 'aayat farz hwin pakistan'),\n",
       " ('typing ka pehla zeena', 'typing ka zair'),\n",
       " ('setaaray un ke naazuk paiir', 'setaaray un naazuk naazuk paiir'),\n",
       " ('khud ko zaat mein ik karwan hon', 'khud ko zaat mein ik karwan hon'),\n",
       " ('hum aisay bhoolnay walay nahi they', 'hum aisay bhoolnay walay nahi they'),\n",
       " ('uday wall soonahre', '- ani utaara se ga'),\n",
       " ('Itra ke chal di kahan', 'utar ke nahi di kahan'),\n",
       " ('jee ki mazaar shareef hi hai', 'jee ki josh shareef hi hai'),\n",
       " ('husn aloy , July 31 , 2008', 'husn aloy , july 31 , 2008'),\n",
       " ('Surriya ki guria', '- bhook ka'),\n",
       " ('bhala kya ki roshan kere ga apne ko',\n",
       "  'bhala kya ki roshan kere ga apne ko'),\n",
       " ('reaya abhi taq', 'ki nahi'),\n",
       " ('baba aisay nahi kehte !', 'becharay to hum kaisi aitraaf'),\n",
       " ('lekin aapko sa sa kharcha karna hoga',\n",
       "  'lekin aapko sa sa kharcha karna hoga'),\n",
       " ('hai chaar din ki hamari ne', 'hai chaar din ki hamari ne'),\n",
       " ('Saima Shah , feb 16 , 2012', 'saima shah , feb 16 , 2012'),\n",
       " ('safha 44 se safha 58 taq', 'safha 44 january 58 58 taq'),\n",
       " ('yahan bhi barish horahee hai', 'yahan to khusi horahee hai'),\n",
       " ('naqsh : tasweer', 'qayamat haasil'),\n",
       " ('Ali baba , April 2 , 2006', 'ali baba , april 2 , 2006'),\n",
       " ('mustaqil nahi hota', 'wahan aaya herani'),\n",
       " ('sab se kam over mein khatam 10', 'sab se kam over mein khatam 10'),\n",
       " ('aish milta hai khaas logon ko', 'aish hota hai khaas logon ko'),\n",
       " ('4 deal astin janoobi Africa 663', '4 deal astin janoobi africa 663'),\n",
       " ('( Danish )', '( 09'),\n",
       " ('lehed mein peda honay walay bachay', 'lehed mein shifa honay walay bachay'),\n",
       " ('mit nahi sakta kabhi mard musalman ke hai',\n",
       "  'mit nahi sakta kabhi mard musalman ke hai'),\n",
       " ('bohat nazar Mirza sahib', 'barri hai tabesh ahmed'),\n",
       " ('lekin ki zurori to nahi na janab', 'lekin ki zurori to nahi na janab'),\n",
       " ('aaj kya khota hai', 'mera to hai taajjub'),\n",
       " ('jata hai do hazaar tera bhi', 'jata hai do hazaar tera bhi'),\n",
       " ('aap sunaaiye aap kaisi hain', 'aap to bhabhee kaisi hain'),\n",
       " ('to biwi safha 82', 'balkay biwi , 2005'),\n",
       " ('islami mumalik ki difai dil', 'islami mumalik par ubhra dil'),\n",
       " ('muki , July 8 , 2011', 'muki , july 8 , 2011'),\n",
       " ('sipahi true aunti', 'parh hwin'),\n",
       " ('raat ki kalak siyasat par thop di', 'raat ki girift siyasat par utarti di'),\n",
       " ('mehfhil par doosri saalgirah mubarak ho qaisrani',\n",
       "  'mehfhil par doosri saalgirah mubarak ho qaisrani'),\n",
       " ('hamari ki to ab yahin munasib lagti hai',\n",
       "  'hamari ki to ab yahin munasib lagti hai'),\n",
       " ('jo apne aap mein raakh ka samandar hain',\n",
       "  'jo apne aap mein raakh ka samandar hain'),\n",
       " ('Shahid afridi bay Zahir 10 14 1 0', 'shahid afridi bay 29 10 14 1 0'),\n",
       " ('acha acha socha karen baba', 'hai to acha karen baba'),\n",
       " ('aap ke liye aik shair', 'ke dobarah dosra aik shair'),\n",
       " ('iqtabas kaisay karna he', 'hai khana baat he'),\n",
       " ('aks ain , September 5 , 2009', 'aks ain , september 5 , 2009'),\n",
       " ('mushawarat ke tareeq mein', 'noon - hwa se roshni')]"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate the prediction\n",
    "preds_bucket_greedy = predict_greedy(test_buckets[current_index][0:100])\n",
    "preds_bucket_greedy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WwG2qsPJdBmL",
    "outputId": "138d143e-75f2-4566-a7de-1728606d1aa9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "greedy search\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU SCORE OF BUCKET SIZE 10: 54.66639309944521\n",
      "ROUGE SCORE OF BUCKET SIZE 10: {'rouge1': 0.6353253968253969, 'rouge2': 0.51879329004329, 'rougeL': 0.6364694749694749, 'rougeLsum': 0.6369771062271061}\n"
     ]
    }
   ],
   "source": [
    "# quantitaive analysis - bleu score of model, rouge score\n",
    "print('greedy search')\n",
    "bleu_score = calculate_bleu_score(preds_bucket_greedy)\n",
    "rouge = evaluate.load('rouge')\n",
    "expected = [pair[0] for pair in preds_bucket_greedy]\n",
    "predicted = [pair[1] for pair in preds_bucket_greedy]\n",
    "rouge_score = rouge.compute(predictions=predicted, references=expected)\n",
    "print(\"BLEU SCORE OF BUCKET SIZE 10:\", bleu_score)\n",
    "print(\"ROUGE SCORE OF BUCKET SIZE 10:\", rouge_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4WbjheUZ2lCF",
    "outputId": "787972bd-6da5-499e-d59d-32cd7537587b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Urdu Sentence: اپ کے لیے ایک شعر\n",
      "Actual Roman Urdu Sentence: aap ke liye aik shair\n",
      "Predicted Roman Urdu Sentence: ke dobarah dosra aik shair\n",
      "\n",
      "Urdu Sentence: اچانک نظر کا پڑنا اور ناپسندیدہ نظر\n",
      "Actual Roman Urdu Sentence: achanak nazar ka parna aur napasandeedah nazar\n",
      "Predicted Roman Urdu Sentence: achanak nazar ka merg aur toseefi nazar\n",
      "\n",
      "Urdu Sentence: مصطفی زیدی ( 1 )\n",
      "Actual Roman Urdu Sentence: mustafa Hussain ( 1 )\n",
      "Predicted Roman Urdu Sentence: raahat hussain 56 1 )\n",
      "\n",
      "Urdu Sentence: یہاں بھی بارش ہورہی ہے\n",
      "Actual Roman Urdu Sentence: yahan bhi barish horahee hai\n",
      "Predicted Roman Urdu Sentence: yahan to khusi horahee hai\n",
      "\n",
      "Urdu Sentence: اقتباس کیسے کرنا ھے\n",
      "Actual Roman Urdu Sentence: iqtabas kaisay karna he\n",
      "Predicted Roman Urdu Sentence: hai khana baat he\n",
      "\n",
      "Urdu Sentence: مستقل نہیں ہوتا\n",
      "Actual Roman Urdu Sentence: mustaqil nahi hota\n",
      "Predicted Roman Urdu Sentence: wahan aaya herani\n",
      "\n",
      "Urdu Sentence: محفل میں اپ کا خیر مقدم ہے\n",
      "Actual Roman Urdu Sentence: mehfhil mein aap ka kher muqaddam hai\n",
      "Predicted Roman Urdu Sentence: mehfhil mein aap ka kher muqaddam hai\n",
      "\n",
      "Urdu Sentence: پھر اسی بے وفا پہ مرتے ہیں\n",
      "Actual Roman Urdu Sentence: phir isi be abbu pay martay hain\n",
      "Predicted Roman Urdu Sentence: phir isi be abbu pay martay hain\n",
      "\n",
      "Urdu Sentence: اگلے سبق میں کتنی دیر ہے استاد محترم\n",
      "Actual Roman Urdu Sentence: aglay sabaq mein kitni der hai ustaad mohtaram\n",
      "Predicted Roman Urdu Sentence: aglay sabaq mein kitni der hai ustaad mohtaram\n",
      "\n",
      "Urdu Sentence: گفتگو میں عجب فصاحت تھی\n",
      "Actual Roman Urdu Sentence: guftagu mein ajab fasahat bhi\n",
      "Predicted Roman Urdu Sentence: par aisi himayat , bhi\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# qualitative analysis - lets see a few example sentences and their transliterations\n",
    "# since greedy gave better performance on quant. metrics, we are just showing the sentences using greedy approach.\n",
    "for i in range(10):\n",
    "  inx = random.randint(0, len(preds_bucket_greedy))\n",
    "  r, u = test_buckets[current_index][inx]\n",
    "  print('Urdu Sentence:', u.replace('<start>', '').replace('<end>', '').strip())\n",
    "  print('Actual Roman Urdu Sentence:', r.replace('<start>', '').replace('<end>', '').strip())\n",
    "  orig, pred = preds_bucket_greedy[inx]\n",
    "  print('Predicted Roman Urdu Sentence:', pred.replace('<start>', '').replace('<end>', '').strip())\n",
    "  print()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
