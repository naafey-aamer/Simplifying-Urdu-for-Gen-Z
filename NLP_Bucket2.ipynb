{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "l3CV8dRIyxJM"
      },
      "source": [
        "# NLP Project\n",
        "\n",
        "Urdu to Roman Urdu Transliterator\n",
        "\n",
        "Help Reference:\n",
        "https://www.tensorflow.org/addons/tutorials/networks_seq2seq_nmt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XgI4xaa7wN43"
      },
      "source": [
        "### This notebook contains the training, evaluation, and testing of the model for sentences of length <= 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d5GXHbPawpq-",
        "outputId": "9e32d772-b7e7-4194-c4e4-dd8683774310"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorflow-addons\n",
            "  Downloading tensorflow_addons-0.20.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (591 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m591.0/591.0 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow-addons) (23.1)\n",
            "Collecting typeguard<3.0.0,>=2.7\n",
            "  Downloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n",
            "Installing collected packages: typeguard, tensorflow-addons\n",
            "Successfully installed tensorflow-addons-0.20.0 typeguard-2.13.3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
            "\n",
            "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
            "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
            "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
            "\n",
            "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
            "\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting evaluate\n",
            "  Downloading evaluate-0.4.0-py3-none-any.whl (81 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.4/81.4 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting huggingface-hub>=0.7.0\n",
            "  Downloading huggingface_hub-0.14.1-py3-none-any.whl (224 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting responses<0.19\n",
            "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.27.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from evaluate) (1.5.3)\n",
            "Requirement already satisfied: fsspec[http]>=2021.05.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2023.4.0)\n",
            "Collecting xxhash\n",
            "  Downloading xxhash-3.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.5/212.5 kB\u001b[0m \u001b[31m23.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting datasets>=2.0.0\n",
            "  Downloading datasets-2.12.0-py3-none-any.whl (474 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m474.6/474.6 kB\u001b[0m \u001b[31m46.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting dill\n",
            "  Downloading dill-0.3.6-py3-none-any.whl (110 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 kB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from evaluate) (4.65.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from evaluate) (23.1)\n",
            "Collecting multiprocess\n",
            "  Downloading multiprocess-0.70.14-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.3/134.3 kB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from evaluate) (1.22.4)\n",
            "Collecting aiohttp\n",
            "  Downloading aiohttp-3.8.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m52.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (6.0)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (9.0.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.7.0->evaluate) (3.12.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (1.26.15)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2022.12.7)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2022.7.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2.8.2)\n",
            "Collecting yarl<2.0,>=1.0\n",
            "  Downloading yarl-1.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m30.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiosignal>=1.1.2\n",
            "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
            "Collecting async-timeout<5.0,>=4.0.0a3\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Collecting frozenlist>=1.1.1\n",
            "  Downloading frozenlist-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (149 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.6/149.6 kB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-6.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.1.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->evaluate) (1.16.0)\n",
            "Installing collected packages: xxhash, multidict, frozenlist, dill, async-timeout, yarl, responses, multiprocess, huggingface-hub, aiosignal, aiohttp, datasets, evaluate\n",
            "Successfully installed aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 datasets-2.12.0 dill-0.3.6 evaluate-0.4.0 frozenlist-1.3.3 huggingface-hub-0.14.1 multidict-6.0.4 multiprocess-0.70.14 responses-0.18.0 xxhash-3.2.0 yarl-1.9.2\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting rouge_score\n",
            "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.4.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from rouge_score) (3.8.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.22.4)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.16.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (8.1.3)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (2022.10.31)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (1.2.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (4.65.0)\n",
            "Building wheels for collected packages: rouge_score\n",
            "  Building wheel for rouge_score (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for rouge_score: filename=rouge_score-0.1.2-py3-none-any.whl size=24954 sha256=bc9f0f24a48f2b50b878af75c070fd0e908d63a94ebacc812c6dbb152582a773\n",
            "  Stored in directory: /root/.cache/pip/wheels/5f/dd/89/461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4\n",
            "Successfully built rouge_score\n",
            "Installing collected packages: rouge_score\n",
            "Successfully installed rouge_score-0.1.2\n"
          ]
        }
      ],
      "source": [
        "# imports \n",
        "import csv\n",
        "import pickle\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Bidirectional\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras import Input\n",
        "from tensorflow.keras.layers import Concatenate, Attention\n",
        "!pip install tensorflow-addons\n",
        "import tensorflow_addons as tfa\n",
        "from tensorflow_addons.seq2seq import BasicDecoder\n",
        "from keras.losses import SparseCategoricalCrossentropy\n",
        "import time as time\n",
        "import nltk\n",
        "from nltk.translate.bleu_score import corpus_bleu, sentence_bleu\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "import random\n",
        "!pip install evaluate\n",
        "import evaluate\n",
        "!pip install rouge_score\n",
        "import numpy as np\n",
        "import heapq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xubph_IswbCg",
        "outputId": "add099e2-83ee-4e4a-e08c-8fb9f2b087e8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# colab\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "35LlhcvSwddg"
      },
      "outputs": [],
      "source": [
        "# load datasets\n",
        "with open('/content/drive/MyDrive/NLP Project/cleaned_data/buckets_train_roman.csv', 'r') as f:\n",
        "    reader = csv.reader(f)\n",
        "    buckets_train_roman = [[[int(num) for num in sublist.split(',')] for sublist in row] for row in reader]\n",
        "\n",
        "with open('/content/drive/MyDrive/NLP Project/cleaned_data/buckets_train_urdu.csv', 'r') as f:\n",
        "    reader = csv.reader(f)\n",
        "    buckets_train_urdu = [[[int(num) for num in sublist.split(',')] for sublist in row] for row in reader]\n",
        "\n",
        "with open('/content/drive/MyDrive/NLP Project/cleaned_data/buckets_test_roman.csv', 'r') as f:\n",
        "    reader = csv.reader(f)\n",
        "    buckets_test_roman = [[[int(num) for num in sublist.split(',')] for sublist in row] for row in reader]\n",
        "\n",
        "with open('/content/drive/MyDrive/NLP Project/cleaned_data/buckets_test_urdu.csv', 'r') as f:\n",
        "    reader = csv.reader(f)\n",
        "    buckets_test_urdu = [[[int(num) for num in sublist.split(',')] for sublist in row] for row in reader]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "03IdnXXxxCLq",
        "outputId": "767443be-a12c-491c-ec45-332109e7152c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "108258"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# just printing to see if i didnt mess up anything\n",
        "len(buckets_train_roman[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Ppw5BjZHzwrc"
      },
      "outputs": [],
      "source": [
        "# ok, i didn't mess up anything - now time to build the tensorflow dataset for the model\n",
        "\n",
        "current_index = 1 # this line is to be changed for each file\n",
        "\n",
        "# hyperparameters for the dataset\n",
        "buffer_size = 32000\n",
        "batch_size = 64\n",
        "\n",
        "# make tensorflow train and test dataset from the buckets, shuffle the train data and convert all datasets to batches of size 64 (as done in the paper)\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((buckets_train_urdu[current_index], buckets_train_roman[current_index]))\n",
        "train_dataset = train_dataset.shuffle(buffer_size).batch(batch_size, drop_remainder=True)\n",
        "\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((buckets_test_urdu[current_index], buckets_test_roman[current_index]))\n",
        "test_dataset = test_dataset.batch(batch_size, drop_remainder=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "XqGzxUwJ11kK"
      },
      "outputs": [],
      "source": [
        "# load the tokenizers\n",
        "with open('/content/drive/MyDrive/NLP Project/tokenizer_roman.pkl', 'rb') as f:\n",
        "    tokenizer_roman_string = f.read()\n",
        "\n",
        "tokenizer_roman = pickle.loads(tokenizer_roman_string)\n",
        "\n",
        "with open('/content/drive/MyDrive/NLP Project/tokenizer_urdu.pkl', 'rb') as f:\n",
        "    tokenizer_urdu_string = f.read()\n",
        "\n",
        "tokenizer_urdu = pickle.loads(tokenizer_urdu_string)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "yOeKkuDD0-js"
      },
      "outputs": [],
      "source": [
        "# hyperparameters for the model\n",
        "vocab_tar_size = len(tokenizer_roman.word_index) + 1\n",
        "vocab_inp_size = len(tokenizer_urdu.word_index) + 1\n",
        "embedding_dim = 256\n",
        "units = 1024\n",
        "steps_per_epoch = 17300 "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jSdxHDda5PWx"
      },
      "source": [
        "## Model Architecture:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "8_GCDDTJDSjc"
      },
      "outputs": [],
      "source": [
        "# code used from the help reference and modified a bit to fit our needs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "3i5mOeihkZKF"
      },
      "outputs": [],
      "source": [
        "# encoder\n",
        "class Encoder(Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz, num_layers=3):\n",
        "      super(Encoder, self).__init__()\n",
        "      self.batch_sz = batch_sz\n",
        "      self.enc_units = enc_units\n",
        "      self.embedding = Embedding(vocab_size, embedding_dim)\n",
        "      self.num_layers = num_layers\n",
        "      # bidirectional lstms, number of layers is passed from arguments\n",
        "      self.lstms = [Bidirectional(LSTM(self.enc_units, return_sequences=True, return_state=True)) for i in range(self.num_layers)]\n",
        "\n",
        "  # custom feedforward function\n",
        "  def call(self, x, hidden):\n",
        "    x = self.embedding(x)\n",
        "    states = hidden\n",
        "    new_states = []\n",
        "    # for each bi_lstm layer, pass in the initial_state from the encoder's hidden state and then get the forward activation, concatenate backward and forward activation\n",
        "    for i in range(self.num_layers):\n",
        "        forward_init_state = states[i*4:i*4+2]\n",
        "        backward_init_state = states[i*4+2:i*4+4]\n",
        "        x, forward_h, forward_c, backward_h, backward_c = self.lstms[i](x, initial_state=forward_init_state + backward_init_state)\n",
        "        h = Concatenate()([forward_h, backward_h])\n",
        "        c = Concatenate()([forward_c, backward_c])\n",
        "        new_states.extend([h, c])\n",
        "    return x, new_states\n",
        "\n",
        "  def build_initial_states(self, batch_sz):\n",
        "      return [tf.zeros((batch_sz, self.enc_units)) for _ in range(self.num_layers * 4)]  # 4 initial states (2 for each lstm layer) per layer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "xvo-GHrUknzt"
      },
      "outputs": [],
      "source": [
        "# decoder\n",
        "class Decoder(Model):\n",
        "    def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz, num_layers):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.batch_sz = batch_sz\n",
        "        self.dec_units = dec_units\n",
        "        self.embedding = Embedding(vocab_size, embedding_dim)\n",
        "        self.num_layers = num_layers\n",
        "        # lstm layers\n",
        "        self.lstms = [LSTM(self.dec_units, return_sequences=True, return_state=True) for _ in range(self.num_layers)]\n",
        "        # output layer\n",
        "        self.fc = Dense(vocab_size)\n",
        "        # attention layer\n",
        "        self.attention = Attention()\n",
        "\n",
        "    # feedforward function \n",
        "    def call(self, x, hidden, enc_output):\n",
        "        # get the context vector from the query asked and the output of the encoder\n",
        "        query = tf.expand_dims(hidden[0], 1)\n",
        "        context_vector = self.attention([query, enc_output])\n",
        "        # add the context vector as input to the decoder\n",
        "        x = self.embedding(x)\n",
        "        x = tf.concat([context_vector, x], axis=-1)\n",
        "\n",
        "        states = hidden\n",
        "        for i in range(self.num_layers):\n",
        "            x, h, c = self.lstms[i](x, initial_state=states[i*2:i*2+2])\n",
        "            states[i*2:i*2+2] = [h, c]\n",
        "\n",
        "        output = tf.reshape(x, (-1, x.shape[2]))\n",
        "        x = self.fc(output)\n",
        "\n",
        "        return x, states\n",
        "\n",
        "    def build_initial_states(self, enc_hidden):\n",
        "        return enc_hidden"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "uaq0XRNsDLXu"
      },
      "outputs": [],
      "source": [
        "# define Adam optimizer and use params given in paper\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ba5QAj4_GD4R"
      },
      "source": [
        "## Train and Evaluate Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "pw9RCe2aDhyg"
      },
      "outputs": [],
      "source": [
        "# define the loss function - code used from help reference\n",
        "def loss_function(real, pred):\n",
        "  # multi-class classification\n",
        "  cross_entropy = SparseCategoricalCrossentropy(from_logits=True, reduction='none')\n",
        "  loss = cross_entropy(y_true=real, y_pred=pred)\n",
        "  # ignore the effect of padded 0s\n",
        "  mask = tf.logical_not(tf.math.equal(real, 0))  \n",
        "  mask = tf.cast(mask, dtype=loss.dtype)  \n",
        "  loss = mask* loss\n",
        "  loss = tf.reduce_mean(loss)\n",
        "  return loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "rsEtgsr9ky0J"
      },
      "outputs": [],
      "source": [
        "# helper function to train each batch\n",
        "@tf.function\n",
        "def train_step(inp, targ, enc_hidden):\n",
        "    loss = 0\n",
        "    # pass input to encoder, get the output from the encoder and pass as input to the decoder\n",
        "    with tf.GradientTape() as tape:\n",
        "        enc_output, enc_hidden = encoder(inp, enc_hidden)\n",
        "        dec_hidden = enc_hidden\n",
        "        dec_input = tf.expand_dims([tokenizer_roman.word_index['<start>']] * batch_size, 1)\n",
        "\n",
        "        for t in range(1, targ.shape[1]):\n",
        "            predictions, dec_hidden = decoder(dec_input, dec_hidden, enc_output)\n",
        "            loss += loss_function(targ[:, t], predictions)\n",
        "            dec_input = tf.expand_dims(targ[:, t], 1)\n",
        "\n",
        "        batch_loss = (loss / int(targ.shape[1]))\n",
        "        # update training parameters (kind of like theta := theta + gradient)\n",
        "        variables = encoder.trainable_variables + decoder.trainable_variables\n",
        "        gradients = tape.gradient(loss, variables)\n",
        "        optimizer.apply_gradients(zip(gradients, variables))\n",
        "\n",
        "        return batch_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kOsaNga1Echm",
        "outputId": "517c06d6-394f-4cb7-fbb6-618e34d37fa0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "total batches: 1691\n",
            "Epoch 1 Batch 0 Loss 6.2469\n",
            "Epoch 1 Batch 1 Loss 4.2466\n",
            "Epoch 1 Batch 2 Loss 3.9152\n",
            "Epoch 1 Batch 3 Loss 3.8013\n",
            "Epoch 1 Batch 4 Loss 3.8534\n",
            "Epoch 1 Batch 5 Loss 3.8189\n",
            "Epoch 1 Batch 6 Loss 4.0218\n",
            "Epoch 1 Batch 7 Loss 3.9583\n",
            "Epoch 1 Batch 8 Loss 3.7587\n",
            "Epoch 1 Batch 9 Loss 3.6304\n",
            "Epoch 1 Batch 10 Loss 3.7665\n",
            "Epoch 1 Batch 11 Loss 3.8224\n",
            "Epoch 1 Batch 12 Loss 3.9083\n",
            "Epoch 1 Batch 13 Loss 3.5639\n",
            "Epoch 1 Batch 14 Loss 3.7009\n",
            "Epoch 1 Batch 15 Loss 3.6634\n",
            "Epoch 1 Batch 16 Loss 3.5514\n",
            "Epoch 1 Loss 0.3711\n",
            "Time taken for 1 epoch 1497.09 sec\n",
            "\n",
            "Epoch 2 Batch 0 Loss 3.5026\n",
            "Epoch 2 Batch 1 Loss 3.6420\n",
            "Epoch 2 Batch 2 Loss 3.4259\n",
            "Epoch 2 Batch 3 Loss 3.1534\n",
            "Epoch 2 Batch 4 Loss 3.3558\n",
            "Epoch 2 Batch 5 Loss 3.3514\n",
            "Epoch 2 Batch 6 Loss 3.4160\n",
            "Epoch 2 Batch 7 Loss 3.3172\n",
            "Epoch 2 Batch 8 Loss 3.4548\n",
            "Epoch 2 Batch 9 Loss 3.1576\n",
            "Epoch 2 Batch 10 Loss 3.2865\n",
            "Epoch 2 Batch 11 Loss 3.3021\n",
            "Epoch 2 Batch 12 Loss 3.1475\n",
            "Epoch 2 Batch 13 Loss 3.0404\n",
            "Epoch 2 Batch 14 Loss 3.3295\n",
            "Epoch 2 Batch 15 Loss 3.1499\n",
            "Epoch 2 Batch 16 Loss 3.0117\n",
            "Epoch 2 Loss 0.3239\n",
            "Time taken for 1 epoch 1435.71 sec\n",
            "\n",
            "Epoch 3 Batch 0 Loss 3.2785\n",
            "Epoch 3 Batch 1 Loss 2.8899\n",
            "Epoch 3 Batch 2 Loss 2.9362\n",
            "Epoch 3 Batch 3 Loss 3.2287\n",
            "Epoch 3 Batch 4 Loss 2.8407\n",
            "Epoch 3 Batch 5 Loss 3.0771\n",
            "Epoch 3 Batch 6 Loss 3.1387\n",
            "Epoch 3 Batch 7 Loss 3.0086\n",
            "Epoch 3 Batch 8 Loss 2.7524\n",
            "Epoch 3 Batch 9 Loss 2.9535\n",
            "Epoch 3 Batch 10 Loss 2.9048\n",
            "Epoch 3 Batch 11 Loss 2.9438\n",
            "Epoch 3 Batch 12 Loss 2.6193\n",
            "Epoch 3 Batch 13 Loss 2.3238\n",
            "Epoch 3 Batch 14 Loss 2.6666\n",
            "Epoch 3 Batch 15 Loss 2.7312\n",
            "Epoch 3 Batch 16 Loss 2.4626\n",
            "Epoch 3 Loss 0.2799\n",
            "Time taken for 1 epoch 1440.69 sec\n",
            "\n",
            "Epoch 4 Batch 0 Loss 2.4075\n",
            "Epoch 4 Batch 1 Loss 2.4760\n",
            "Epoch 4 Batch 2 Loss 2.3456\n",
            "Epoch 4 Batch 3 Loss 2.1629\n",
            "Epoch 4 Batch 4 Loss 2.3850\n",
            "Epoch 4 Batch 5 Loss 2.1438\n",
            "Epoch 4 Batch 6 Loss 1.9507\n",
            "Epoch 4 Batch 7 Loss 1.9715\n",
            "Epoch 4 Batch 8 Loss 2.1538\n",
            "Epoch 4 Batch 9 Loss 1.8898\n",
            "Epoch 4 Batch 10 Loss 2.0420\n",
            "Epoch 4 Batch 11 Loss 1.7985\n",
            "Epoch 4 Batch 12 Loss 1.6842\n",
            "Epoch 4 Batch 13 Loss 1.8005\n",
            "Epoch 4 Batch 14 Loss 1.8367\n",
            "Epoch 4 Batch 15 Loss 1.9239\n",
            "Epoch 4 Batch 16 Loss 3.6525\n",
            "Epoch 4 Loss 0.1994\n",
            "Time taken for 1 epoch 1443.50 sec\n",
            "\n",
            "Epoch 5 Batch 0 Loss 1.8299\n",
            "Epoch 5 Batch 1 Loss 1.8583\n",
            "Epoch 5 Batch 2 Loss 1.4807\n",
            "Epoch 5 Batch 3 Loss 1.6125\n",
            "Epoch 5 Batch 4 Loss 1.4689\n",
            "Epoch 5 Batch 5 Loss 1.5291\n",
            "Epoch 5 Batch 6 Loss 1.4834\n",
            "Epoch 5 Batch 7 Loss 1.6928\n",
            "Epoch 5 Batch 8 Loss 1.6805\n",
            "Epoch 5 Batch 9 Loss 1.5255\n",
            "Epoch 5 Batch 10 Loss 1.5066\n",
            "Epoch 5 Batch 11 Loss 1.1783\n",
            "Epoch 5 Batch 12 Loss 1.6254\n",
            "Epoch 5 Batch 13 Loss 1.4775\n",
            "Epoch 5 Batch 14 Loss 1.4817\n",
            "Epoch 5 Batch 15 Loss 1.2291\n",
            "Epoch 5 Batch 16 Loss 1.3585\n",
            "Epoch 5 Loss 0.1510\n",
            "Time taken for 1 epoch 1439.53 sec\n",
            "\n",
            "Epoch 6 Batch 0 Loss 1.2128\n",
            "Epoch 6 Batch 1 Loss 1.1882\n",
            "Epoch 6 Batch 2 Loss 1.2672\n",
            "Epoch 6 Batch 3 Loss 1.2853\n",
            "Epoch 6 Batch 4 Loss 1.1753\n",
            "Epoch 6 Batch 5 Loss 1.1869\n",
            "Epoch 6 Batch 6 Loss 1.1614\n",
            "Epoch 6 Batch 7 Loss 1.0777\n",
            "Epoch 6 Batch 8 Loss 1.0507\n",
            "Epoch 6 Batch 9 Loss 1.5519\n",
            "Epoch 6 Batch 10 Loss 1.0049\n",
            "Epoch 6 Batch 11 Loss 1.3722\n",
            "Epoch 6 Batch 12 Loss 2.0944\n",
            "Epoch 6 Batch 13 Loss 1.1969\n",
            "Epoch 6 Batch 14 Loss 1.0658\n",
            "Epoch 6 Batch 15 Loss 1.3735\n",
            "Epoch 6 Batch 16 Loss 1.0065\n",
            "Epoch 6 Loss 0.1259\n",
            "Time taken for 1 epoch 1442.37 sec\n",
            "\n",
            "Epoch 7 Batch 0 Loss 0.9119\n",
            "Epoch 7 Batch 1 Loss 0.9396\n",
            "Epoch 7 Batch 2 Loss 0.8627\n",
            "Epoch 7 Batch 3 Loss 0.9741\n",
            "Epoch 7 Batch 4 Loss 1.0433\n",
            "Epoch 7 Batch 5 Loss 1.0625\n",
            "Epoch 7 Batch 6 Loss 1.0659\n",
            "Epoch 7 Batch 7 Loss 0.8910\n",
            "Epoch 7 Batch 8 Loss 0.7690\n",
            "Epoch 7 Batch 9 Loss 0.9252\n",
            "Epoch 7 Batch 10 Loss 0.8769\n",
            "Epoch 7 Batch 11 Loss 0.8408\n",
            "Epoch 7 Batch 12 Loss 0.8119\n",
            "Epoch 7 Batch 13 Loss 0.6671\n",
            "Epoch 7 Batch 14 Loss 0.6187\n",
            "Epoch 7 Batch 15 Loss 0.7857\n",
            "Epoch 7 Batch 16 Loss 0.7323\n",
            "Epoch 7 Loss 0.0923\n",
            "Time taken for 1 epoch 1441.93 sec\n",
            "\n",
            "Epoch 8 Batch 0 Loss 0.8669\n",
            "Epoch 8 Batch 1 Loss 0.7106\n",
            "Epoch 8 Batch 2 Loss 0.7511\n",
            "Epoch 8 Batch 3 Loss 0.6649\n",
            "Epoch 8 Batch 4 Loss 0.7878\n",
            "Epoch 8 Batch 5 Loss 0.7110\n",
            "Epoch 8 Batch 6 Loss 0.7564\n",
            "Epoch 8 Batch 7 Loss 0.7292\n",
            "Epoch 8 Batch 8 Loss 0.6922\n",
            "Epoch 8 Batch 9 Loss 0.5592\n",
            "Epoch 8 Batch 10 Loss 0.6197\n",
            "Epoch 8 Batch 11 Loss 0.6312\n",
            "Epoch 8 Batch 12 Loss 0.5096\n",
            "Epoch 8 Batch 13 Loss 0.7610\n",
            "Epoch 8 Batch 14 Loss 0.5483\n",
            "Epoch 8 Batch 15 Loss 0.5475\n",
            "Epoch 8 Batch 16 Loss 0.5631\n",
            "Epoch 8 Loss 0.0641\n",
            "Time taken for 1 epoch 1441.69 sec\n",
            "\n",
            "Epoch 9 Batch 0 Loss 0.4009\n",
            "Epoch 9 Batch 1 Loss 0.5945\n",
            "Epoch 9 Batch 2 Loss 0.4643\n",
            "Epoch 9 Batch 3 Loss 0.4847\n",
            "Epoch 9 Batch 4 Loss 0.5100\n",
            "Epoch 9 Batch 5 Loss 0.7204\n",
            "Epoch 9 Batch 6 Loss 0.4341\n",
            "Epoch 9 Batch 7 Loss 0.4196\n",
            "Epoch 9 Batch 8 Loss 0.4383\n",
            "Epoch 9 Batch 9 Loss 0.3703\n",
            "Epoch 9 Batch 10 Loss 0.3958\n",
            "Epoch 9 Batch 11 Loss 0.3356\n",
            "Epoch 9 Batch 12 Loss 0.3345\n",
            "Epoch 9 Batch 13 Loss 0.3498\n",
            "Epoch 9 Batch 14 Loss 0.4517\n",
            "Epoch 9 Batch 15 Loss 0.4557\n",
            "Epoch 9 Batch 16 Loss 0.3961\n",
            "Epoch 9 Loss 0.0444\n",
            "Time taken for 1 epoch 1440.51 sec\n",
            "\n",
            "Epoch 10 Batch 0 Loss 0.9204\n",
            "Epoch 10 Batch 1 Loss 0.3929\n",
            "Epoch 10 Batch 2 Loss 0.4748\n",
            "Epoch 10 Batch 3 Loss 0.3883\n",
            "Epoch 10 Batch 4 Loss 0.3134\n",
            "Epoch 10 Batch 5 Loss 0.3783\n",
            "Epoch 10 Batch 6 Loss 0.3614\n",
            "Epoch 10 Batch 7 Loss 0.3380\n",
            "Epoch 10 Batch 8 Loss 0.3409\n",
            "Epoch 10 Batch 9 Loss 0.2712\n",
            "Epoch 10 Batch 10 Loss 0.3256\n",
            "Epoch 10 Batch 11 Loss 0.3335\n",
            "Epoch 10 Batch 12 Loss 1.1139\n",
            "Epoch 10 Batch 13 Loss 0.4106\n",
            "Epoch 10 Batch 14 Loss 0.3357\n",
            "Epoch 10 Batch 15 Loss 0.2078\n",
            "Epoch 10 Batch 16 Loss 0.3650\n",
            "Epoch 10 Loss 0.0394\n",
            "Time taken for 1 epoch 1441.59 sec\n",
            "\n",
            "Epoch 11 Batch 0 Loss 0.3024\n",
            "Epoch 11 Batch 1 Loss 0.2141\n",
            "Epoch 11 Batch 2 Loss 0.3904\n",
            "Epoch 11 Batch 3 Loss 0.3190\n",
            "Epoch 11 Batch 4 Loss 0.2607\n",
            "Epoch 11 Batch 5 Loss 0.2770\n",
            "Epoch 11 Batch 6 Loss 0.2399\n",
            "Epoch 11 Batch 7 Loss 0.2772\n",
            "Epoch 11 Batch 8 Loss 0.2541\n",
            "Epoch 11 Batch 9 Loss 0.2607\n",
            "Epoch 11 Batch 10 Loss 0.2032\n",
            "Epoch 11 Batch 11 Loss 0.2169\n",
            "Epoch 11 Batch 12 Loss 0.2903\n",
            "Epoch 11 Batch 13 Loss 0.2854\n",
            "Epoch 11 Batch 14 Loss 0.1620\n",
            "Epoch 11 Batch 15 Loss 0.2140\n",
            "Epoch 11 Batch 16 Loss 0.2164\n",
            "Epoch 11 Loss 0.0242\n",
            "Time taken for 1 epoch 1443.03 sec\n",
            "\n",
            "Epoch 12 Batch 0 Loss 0.1894\n",
            "Epoch 12 Batch 1 Loss 0.1481\n",
            "Epoch 12 Batch 2 Loss 0.1210\n",
            "Epoch 12 Batch 3 Loss 0.1996\n",
            "Epoch 12 Batch 4 Loss 0.1751\n",
            "Epoch 12 Batch 5 Loss 0.1875\n",
            "Epoch 12 Batch 6 Loss 0.2052\n",
            "Epoch 12 Batch 7 Loss 0.1556\n",
            "Epoch 12 Batch 8 Loss 0.1491\n",
            "Epoch 12 Batch 9 Loss 0.2712\n",
            "Epoch 12 Batch 10 Loss 0.2129\n",
            "Epoch 12 Batch 11 Loss 0.2003\n",
            "Epoch 12 Batch 12 Loss 0.0893\n",
            "Epoch 12 Batch 13 Loss 0.1652\n",
            "Epoch 12 Batch 14 Loss 0.1656\n",
            "Epoch 12 Batch 15 Loss 0.1034\n",
            "Epoch 12 Batch 16 Loss 0.1030\n",
            "Epoch 12 Loss 0.0165\n",
            "Time taken for 1 epoch 1439.91 sec\n",
            "\n",
            "Epoch 13 Batch 0 Loss 0.1284\n",
            "Epoch 13 Batch 1 Loss 0.0726\n",
            "Epoch 13 Batch 2 Loss 0.1715\n",
            "Epoch 13 Batch 3 Loss 0.1344\n",
            "Epoch 13 Batch 4 Loss 0.1607\n",
            "Epoch 13 Batch 5 Loss 0.1004\n",
            "Epoch 13 Batch 6 Loss 0.1467\n",
            "Epoch 13 Batch 7 Loss 0.0572\n",
            "Epoch 13 Batch 8 Loss 0.0705\n",
            "Epoch 13 Batch 9 Loss 0.0817\n",
            "Epoch 13 Batch 10 Loss 0.4396\n",
            "Epoch 13 Batch 11 Loss 0.1733\n",
            "Epoch 13 Batch 12 Loss 0.1230\n",
            "Epoch 13 Batch 13 Loss 0.1149\n",
            "Epoch 13 Batch 14 Loss 0.1955\n",
            "Epoch 13 Batch 15 Loss 0.1096\n",
            "Epoch 13 Batch 16 Loss 0.1438\n",
            "Epoch 13 Loss 0.0156\n",
            "Time taken for 1 epoch 1440.86 sec\n",
            "\n",
            "Epoch 14 Batch 0 Loss 0.1163\n",
            "Epoch 14 Batch 1 Loss 0.0678\n",
            "Epoch 14 Batch 2 Loss 0.0870\n",
            "Epoch 14 Batch 3 Loss 0.0786\n",
            "Epoch 14 Batch 4 Loss 0.0645\n",
            "Epoch 14 Batch 5 Loss 0.0654\n",
            "Epoch 14 Batch 6 Loss 0.1163\n",
            "Epoch 14 Batch 7 Loss 0.0666\n",
            "Epoch 14 Batch 8 Loss 0.0961\n",
            "Epoch 14 Batch 9 Loss 0.1221\n",
            "Epoch 14 Batch 10 Loss 0.1531\n",
            "Epoch 14 Batch 11 Loss 0.2703\n",
            "Epoch 14 Batch 12 Loss 0.1914\n",
            "Epoch 14 Batch 13 Loss 0.1014\n",
            "Epoch 14 Batch 14 Loss 0.1998\n",
            "Epoch 14 Batch 15 Loss 0.1172\n",
            "Epoch 14 Batch 16 Loss 0.1002\n",
            "Epoch 14 Loss 0.0110\n",
            "Time taken for 1 epoch 1439.50 sec\n",
            "\n",
            "Epoch 15 Batch 0 Loss 0.0871\n",
            "Epoch 15 Batch 1 Loss 0.0724\n",
            "Epoch 15 Batch 2 Loss 0.0516\n",
            "Epoch 15 Batch 3 Loss 0.0717\n",
            "Epoch 15 Batch 4 Loss 0.0449\n",
            "Epoch 15 Batch 5 Loss 0.0923\n",
            "Epoch 15 Batch 6 Loss 0.0630\n",
            "Epoch 15 Batch 7 Loss 0.0832\n",
            "Epoch 15 Batch 8 Loss 0.0483\n",
            "Epoch 15 Batch 9 Loss 0.0434\n",
            "Epoch 15 Batch 10 Loss 0.0697\n",
            "Epoch 15 Batch 11 Loss 0.1220\n",
            "Epoch 15 Batch 12 Loss 0.0479\n",
            "Epoch 15 Batch 13 Loss 0.0746\n",
            "Epoch 15 Batch 14 Loss 0.0480\n",
            "Epoch 15 Batch 15 Loss 0.0390\n",
            "Epoch 15 Batch 16 Loss 0.0628\n",
            "Epoch 15 Loss 0.0078\n",
            "Time taken for 1 epoch 1438.01 sec\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# main training loop - code modified from help reference\n",
        "import time as time\n",
        "\n",
        "EPOCHS = 15\n",
        "train_loss = []\n",
        "num_layers = 2\n",
        "\n",
        "encoder = Encoder(vocab_inp_size, embedding_dim, units, batch_size, num_layers)\n",
        "decoder = Decoder(vocab_tar_size, embedding_dim, units*2, batch_size, num_layers)\n",
        "print('total batches:', len(train_dataset))\n",
        "for epoch in range(EPOCHS):\n",
        "    start = time.time()\n",
        "\n",
        "    enc_hidden = encoder.build_initial_states(batch_size)\n",
        "    total_loss = 0\n",
        "\n",
        "    for (batch, (inp, targ)) in enumerate(train_dataset.take(steps_per_epoch)):\n",
        "        batch_loss = train_step(inp, targ, enc_hidden)\n",
        "        train_loss.append(batch_loss)\n",
        "        total_loss += batch_loss\n",
        "\n",
        "        if batch % 100 == 0:\n",
        "            print(f'Epoch {epoch+1} Batch {batch // 100} Loss {batch_loss.numpy():.4f}')\n",
        "\n",
        "    print(f'Epoch {epoch+1} Loss {total_loss/steps_per_epoch:.4f}')\n",
        "    print(f'Time taken for 1 epoch {time.time()-start:.2f} sec\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "987tAUP4_2o4"
      },
      "outputs": [],
      "source": [
        "# beam search:\n",
        "import math \n",
        "\n",
        "def predict_beam(test_bucket):\n",
        "  output = []\n",
        "  # iterate through each example\n",
        "  for i, (roman_sentence, urdu_sentence) in enumerate(test_bucket):\n",
        "    # print(i, \"examples done,\", len(test_bucket) - i, \"remain\")\n",
        "    # convert the sentence to its numeric sequence to give to the model\n",
        "    urdu_sequence = [tokenizer_urdu.word_index[i] if i in tokenizer_urdu.word_index else tokenizer_urdu.word_index['<OOV>'] for i in urdu_sentence.split(' ')]\n",
        "    urdu_sequence = pad_sequences([urdu_sequence], padding='post')\n",
        "    # convert the sequence to a tensor\n",
        "    urdu_sequence = tf.convert_to_tensor(urdu_sequence)\n",
        "    inference_batch_size = urdu_sequence.shape[0]\n",
        "    # call the encoder\n",
        "    enc_start_state = [tf.zeros((inference_batch_size, units)) for _ in range(num_layers * 4)]\n",
        "    enc_out, enc_hidden = encoder(urdu_sequence, enc_start_state)\n",
        "    # create input for decoder\n",
        "    dec_hidden = enc_hidden\n",
        "    dec_input = tf.expand_dims([tokenizer_roman.word_index['<start>']] * inference_batch_size, 1)\n",
        "    max_len_output = 20\n",
        "    # get the input sequence for the decoder\n",
        "    input_sequence = dec_input.numpy()\n",
        "    # initialize the candidates from beam search, each row is of type: (candidate_sequence, log_probability)\n",
        "    beam_candidates = [[input_sequence, 0.0]]\n",
        "    beam_width = 5\n",
        "    for t in range(max_len_output):\n",
        "      # store the next candidates\n",
        "      next_candidates = []\n",
        "      # for each sequence in the current list of candidates\n",
        "      for seq, score in beam_candidates:\n",
        "        seq = tf.convert_to_tensor(seq)\n",
        "        dec_input = tf.expand_dims(tf.convert_to_tensor([seq.numpy()[0][-1]]) if len(seq) > 0 else tokenizer_roman.word_index['<start>'], 0)\n",
        "        # get the predictions for each token from the decoder for this sequence\n",
        "        predictions, dec_hidden = decoder(dec_input, dec_hidden, enc_out)\n",
        "        # normalize probabilities to prevent negative values\n",
        "        probs = tf.nn.softmax(predictions, axis=1)\n",
        "        min_len = len(roman_sentence.split(' '))\n",
        "        # punish printing <end> before len(roman_sentence) by assigning it a very log value\n",
        "        if t < min_len:\n",
        "          end_token_inx = tokenizer_roman.word_index['<end>']\n",
        "          mask = tf.one_hot(end_token_inx,probs.shape[-1], dtype=tf.float32)\n",
        "          probs = tf.where(mask == 1, tf.ones_like(probs) * -float('inf'), probs)\n",
        "        # store the top k most probable ones - beam search\n",
        "        top_k_preds = tf.math.top_k(probs[0], k=beam_width)\n",
        "        for current_beam in range(beam_width):\n",
        "          predicted_index = top_k_preds.indices[current_beam].numpy()\n",
        "          candidate_sequence = tf.concat([seq, tf.convert_to_tensor([[predicted_index]])], axis=1)\n",
        "          candidate_score = score + math.log(top_k_preds.values[current_beam])\n",
        "          next_candidates.append([candidate_sequence, candidate_score])\n",
        "        \n",
        "      # sort candidates by their score\n",
        "      sorted_candidates = sorted(next_candidates, key=lambda tup: tup[1], reverse=True)\n",
        "      # get the top beam_width candidates\n",
        "      beam_candidates = sorted_candidates[:beam_width]\n",
        "      # exit loop if all candidates have generated <end> token\n",
        "      # if all([tokenizer_roman.index_word[c[0].numpy()[0][-1]] == '<end>' for c in beam_candidates]):\n",
        "      #   break\n",
        "\n",
        "    # best candidate\n",
        "    best_sequence = beam_candidates[0][0]\n",
        "    result = ' '.join([tokenizer_roman.index_word[idx] for idx in best_sequence.numpy()[0]])\n",
        "    output.append((roman_sentence.replace('<start>', '').replace('<end>', '').strip(), result.replace('<start>', '').replace('<end>', '').strip()))\n",
        "  return output\n",
        "\n",
        "\n",
        "# greedy search:\n",
        "def predict_greedy(test_dataset):\n",
        "  preds_bucket = []\n",
        "  # for each example in the test set\n",
        "  for i, tup in enumerate(test_dataset):\n",
        "    # call the evaluate_sentence func on the urdu text's batch\n",
        "    result = evaluate_sentence(tup[1]).replace(\"<start>\", \"\").replace(\"<end>\", \"\").strip()\n",
        "    expected = tup[0].replace(\"<start>\", \"\").replace(\"<end>\", \"\").strip()\n",
        "    preds_bucket.append((expected, result))\n",
        "    if i % 100 == 0:\n",
        "      print(i, \"test examples done,\", len(test_dataset) - i, \"left.\")\n",
        "  print('all done!')\n",
        "  return preds_bucket\n",
        "\n",
        "def evaluate_sentence(sentence):\n",
        "    inputs = [tokenizer_urdu.word_index[i] if i in tokenizer_urdu.word_index else tokenizer_urdu.word_index['<OOV>'] for i in sentence.split(' ')]\n",
        "    inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs], padding='post')\n",
        "    inputs = tf.convert_to_tensor(inputs)\n",
        "    inference_batch_size = inputs.shape[0]\n",
        "    result = '<start>'\n",
        "    enc_start_state = [tf.zeros((inference_batch_size, units)) for _ in range(num_layers * 4)] \n",
        "    enc_out, enc_hidden = encoder(inputs, enc_start_state)\n",
        "    \n",
        "    dec_hidden = enc_hidden\n",
        "    dec_input = tf.expand_dims([tokenizer_roman.word_index['<start>']] * inference_batch_size, 1)\n",
        "    \n",
        "    for t in range(40):\n",
        "\n",
        "      predictions, dec_hidden = decoder(dec_input, dec_hidden, enc_out) \n",
        "        \n",
        "      # just use argmax to get the token with the highest probability\n",
        "      predicted_id = tf.argmax(predictions, axis=-1).numpy()[0]\n",
        "        \n",
        "      result += tokenizer_roman.index_word[predicted_id] + ' '\n",
        "        \n",
        "      if tokenizer_roman.index_word[predicted_id] == '<end>':\n",
        "          return result.strip()\n",
        "        \n",
        "      # pass the predicted token as the next input to the decoder\n",
        "      dec_input = tf.expand_dims([predicted_id] * inference_batch_size, 1)\n",
        "      \n",
        "    return result\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "FJLg1SkbFkE3"
      },
      "outputs": [],
      "source": [
        "# helper function to calculate bleu score\n",
        "def calculate_bleu_score(preds):\n",
        "  # Split the dataset into expected translations and predicted translations.\n",
        "  expected = [pair[0] for pair in preds]\n",
        "  predicted = [pair[1] for pair in preds]\n",
        "\n",
        "  # # Calculate the BLEU score for each sentence and average BLEU score for all test sentences\n",
        "  bleu_scores = [sentence_bleu([ref.split()], pred.split()) for ref, pred in zip(predicted, expected)]\n",
        "  avg_bleu_score = corpus_bleu([[ref.split()] for ref in expected], [pred.split() for pred in predicted])\n",
        "\n",
        "  return avg_bleu_score * 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "-E4lf5NWG3J2"
      },
      "outputs": [],
      "source": [
        "def loss_graph(train_loss):\n",
        "  train_steps = list(range(len(train_loss)))\n",
        "  # Create the figure and axis objects\n",
        "  fig, ax = plt.subplots()\n",
        "  # Plot the data\n",
        "  ax.plot(train_steps, train_loss, color='blue')\n",
        "  # Set the title and axis labels\n",
        "  ax.set_title('Training Loss')\n",
        "  ax.set_xlabel('Training Steps')\n",
        "  ax.set_ylabel('Training Loss')\n",
        "  # Show the plot\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "NW6s5tcVIMGJ",
        "outputId": "00383ccd-80df-4c13-f69a-dda22db73e05"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# plot the training loss graph\n",
        "loss_graph(train_loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "fGIVWIs7GnHj"
      },
      "outputs": [],
      "source": [
        "# load the test data\n",
        "import pickle\n",
        "\n",
        "with open('/content/drive/MyDrive/NLP Project/test_buckets.pickle', 'rb') as f:\n",
        "    test_buckets = pickle.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mA11LwNiGM31",
        "outputId": "02aafb0e-278d-47e4-bfab-b011a5767359"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('jamaat yani imam ke ilawa kam se kam teen mard',\n",
              "  'jamaat yani se jari hain ke liye jari se hai zila zila'),\n",
              " ('azal se le kar kaamil taq ki badolat ka ghulamana salam qubool kar !',\n",
              "  'azal se hub salam kar rahay ko qubool yi aamad zila ! ki hain ! zila  !'),\n",
              " ('ke be abbu tha magar dost tha purana woh',\n",
              "  'ke be hai dost par grijoyshn ka terhan hai zila zila'),\n",
              " ('aur ab ki imandaar kisi kyun mein nahi kabhi ki cheezein khoobiyan sun - hwa karti theen',\n",
              "  'aur ab jaakar sun - anjaam di liya di ki zaroorat ki wajah ki terhan tahiya liya sakti hain'),\n",
              " ('waisay guria se to kya aap khailtay hon ge bnta kar letay hain tarmeem kar ke : )',\n",
              "  'waisay guria khailtay satke se tahiya ) ) hain ) zila ) hain zila . ) farmaya ) umeed )'),\n",
              " ('ki sach hai naya zee hum sarka ray ka kha te hain',\n",
              "  'ki sach - e baghaawat se hain hain ki tahiya par award hain ki'),\n",
              " ('palat yahan se ! mra sheesha saaf nikla hai',\n",
              "  'palat yahan dil hai zila zila zila zila zila zila zila'),\n",
              " ('woh khud saraab hai ouron ko aabb kya day ga',\n",
              "  'woh khud kabhi nahi hai ki daal yi terhan grijoyshn karna thisishypenhere'),\n",
              " ('to tum kya sara din kamray mein pari rehti ho',\n",
              "  'to tum se theen gaya ki tahiya ho ki hai hoti hain'),\n",
              " ('jhoot ki bhi ki koi hoti hai -',\n",
              "  'jhoot ki hoti hai aur - khaal hai zila zila'),\n",
              " ('mein mehdi ne aik bunyaad daali jo dushmanon ke hamlay mein un ki panah gaah ban sakay',\n",
              "  'mein mehdi jo un hungama ban hain is ban _ hi teen tahiya banay ban _ h ban hai'),\n",
              " ('Zumra jaat : shairi , Farhat abbas Shah , muntakhib kalaam , nazam , nazmein',\n",
              "  'zumra jaat abbas , 97 ke e yi deal yi reading deal yi reading deal yi tahiya'),\n",
              " ('lekin baqi sawalaat kis qisam ke hon ge dara rahen aap to',\n",
              "  'lekin baqi ke to q . ge thisishypenhere bolna kaafi shuru den . thisishypenhere'),\n",
              " ('kahani ka taana baana London ki ryil Azam haath ke gird bana gaya hai aur ko Sabiqa',\n",
              "  'kahani ka israel gaya hai par tha par par mushtamil hai zila hai - zail hai hai par hai'),\n",
              " ('halki barish hui aaj magar sardi qabil bardasht hai',\n",
              "  'rozana magar khaali hai dono feesad liye hai un hai liye   hai   hai'),\n",
              " ('pehlay bhi marey zehan se daari hui bhi',\n",
              "  'pehlay bhi dhund hai ki hai zila zila zila zila'),\n",
              " ('apna aik taaruf mehfhil par shareek kar dun ga',\n",
              "  'apna aik nazar nahi ki nazar nahi ki hai ge zila'),\n",
              " ('maffi chahta hon aap ko jawab dena bhool gaya',\n",
              "  'maffi chahta allah gaya ke tahiya rahay par tahiya mein tahiya'),\n",
              " ('is ki lambai kilometer mil se zayed hai',\n",
              "  'is ki afraad hai is tahiya rahay ki tahiya par'),\n",
              " ('mehnat abad zila lateeni azbkstan ka aik jo sair darya soobah mein waqay hai',\n",
              "  'usmaan abad ka soobah waqay par mein waqay hai karachi mein waqay par waqay mein mein'),\n",
              " ('abhi to mein mehfhil par kal aur aaj ki ziada parhte parhte idhar poanch gaya',\n",
              "  'abhi to par ziada rahen gaya hain aik tahiya hoti hain ki hoti par terhan hoti hain'),\n",
              " ('bohat nazar blaamtyaz bhai mein koshish karta hon',\n",
              "  'bohat nazar mein hai y zila zila zila bhi zila'),\n",
              " ('azeem jheelon mein se payaab tareen jheel hai aur is ki ost geherai meter hai',\n",
              "  'azeem jheelon jheel hai ki yeh hai ki bulandi hai ki tadaad hai ki hai ki tadaad'),\n",
              " ('aik home tution se morad ke apne mamu .',\n",
              "  'aik home ke liye bhi mamu karna mamu den se .'),\n",
              " ('Pakistan ke soobah Sindh ka naqsha zila jacob abad ko numaya kya gaya hai',\n",
              "  'pakistan ke zila mein hai ke gaya hai un hai jata hai ki hai gaya hain  hai'),\n",
              " ('yahan nai tazi abhi to yahi ke sardi bhaag gayi poori terhan',\n",
              "  'yahan nai to ko tahiya karli ko tahiya ko par par ko tahiya par'),\n",
              " ('ishhq ke hain Muajzaat saltanat o fiqr o den',\n",
              "  'ishhq ke ktab ki kamyaab bolna zila ki tahiya se hai'),\n",
              " ('jabkay Iran ne inhen hazaar wapas bhi dhkila aur sazayen bhi den',\n",
              "  'jabkay iran bhi shayad saathi den den shuru den dekhen shuru den ge thisishypenhere   den'),\n",
              " ('ya rab dua hai tujh se ki har dam Anees ki',\n",
              "  'ya rab ki mustaqbil hai ki par farang se qaida par farang par'),\n",
              " ('ab Mohammad sahib ke taaruf ki bhi ki zaroorat hai',\n",
              "  'ab mohammad ki hai - amal hai ke par hai - zila'),\n",
              " ('aur woh bhi poori ne dekh rahi hai is ke mutaliq kya irshad karna jab ge Fawad sahib',\n",
              "  'aur woh ki sawal aapka aapka moazrat zila uf haazir zila darasal zila haazir sahib zila dena zila kaafi zila'),\n",
              " ('ne mamu se sun - hwa kya guzar raat ka',\n",
              "  'ne mamu gaya ho ko hai is hai ke amal ke moaqqaf'),\n",
              " ('matti ki ki mourat hai ki sab tootay gi',\n",
              "  'matti ki sab rahi se hain ki wajah isi nah walay'),\n",
              " ('kam az kam das saal se Pakistan ka shehri aur Pakistan mein sukoonat Pazeer ho',\n",
              "  'kam az se asharih day se khakay ho se aamad mein is se shanakht se ho se'),\n",
              " ('din mein martaba farz namazon ke liye muezzin yeh fareeza injaam deta hai',\n",
              "  'din mein nazar jurm hai ki terhan hai - khaal hai zila zila hai hai   hai'),\n",
              " ('is film mein mustand scienci usool bhi bartay gay',\n",
              "  'is film bhi paye se tahiya shuru den usay tahiya kyagyatha'),\n",
              " ('is ke se Safi ab technology ho chuka hai',\n",
              "  'is ke nahi nahi ke amal hai - amal den zila'),\n",
              " ('aur haan is mehfhil mein anay se pehlay dil insani sabhi frige mein bangal aati hon',\n",
              "  'aur haan se dil hon liye hai . khawab hai . khawab hai . pagal hai lekin liye  hai'),\n",
              " ('chalees - se taq afraad ki halakat ka khadsha ae are why one world',\n",
              "  'chalees - university ka tahiya par janib den taleem haasil ki tahiya ki shakal yi tadaad'),\n",
              " ('kisi mein zar kisi mein sang ki hai phair qismat ka',\n",
              "  'kisi mein ki bayan utthay ke par hai par zila ko hai par'),\n",
              " ('bohat nazar Ahmed bhai is hosla afzai ka',\n",
              "  'bohat nazar ki khitaab shuru ke zila zila y karli'),\n",
              " ('kitaab azbkstan lateeni azbkstan ka aik insani abadkari jo Qushqa darya soobah mein waqay hai',\n",
              "  'kitaab azbkstan hai mein waqay hai shehar mein waqay se waqay par waqay mein grijoyshn mein waqay'),\n",
              " ('nazar Shoiab bhai mein amal kar ke daikhta hon',\n",
              "  'nazar shoiab se grijoyshn par hai ) hon ) hon usay'),\n",
              " ('maarka hai aaj . dekhieye woh kya kere hmm kya karen',\n",
              "  'taba hai aur karen ki tahiya den ki hai ) ! ki hain'),\n",
              " ('mehfhil family awards 15 - fa - aal tareen rahay',\n",
              "  'mehfhil family ship saki ki asraar hain ki aamad ki aamad hai'),\n",
              " ('roz kya din mein teen chaar baar bhi kabhi kabhi',\n",
              "  'roz kya pani ge kabhi thisishypenhere thisishypenhere qaida se award shuru den'),\n",
              " ('jo kho baithy hain ko raah phoolon ke hissaron mein',\n",
              "  'jo kho bhar kar se hain se shuru rahay se kamyaab par'),\n",
              " ('ab ke nah ki qasr nah ewaan bachay ga',\n",
              "  'ab ke zair mojood mlitay se bolna mlitay ki bolna ga'),\n",
              " ('soda kar is se dil ki tasalii ke wastay',\n",
              "  'soda karo ki ke kandhay hai ki tahiya se kaafi terhan'),\n",
              " ('jab ke ne totay ne jo quraa nikala hai is se mujhe ki ishara samajh aaya hai ke',\n",
              "  'jab ke mukhbar haazir aaya n hai . liye hai - amal . - khaal . maloom maloom . ke'),\n",
              " ('Albata agar to ki is line ko cal karne mein bhi use',\n",
              "  'albata agar ko matan ke liye nonehal karli karli karli job karli karli zila'),\n",
              " ('apne shohar ke jawan saal teen ki maa bani aur kuch nah boli -',\n",
              "  'apne shohar ki bhi - ta - zila zaroorat ki zaroorat hai zila zaroorat par hai'),\n",
              " ('un ka intqaal hazrat Umar Farooq ke zamana khilafat mein sun - hwa',\n",
              "  'un ka ab sun - amal gaya mein tahiya mein sun - se sun -'),\n",
              " ('mein ko ekloti behan ko miss kar raha hon !',\n",
              "  'mein ko kar raha ke hai ) zila raha ga zila hai'),\n",
              " ('India ke 16 overs ke ekhtataam par 182 chay 2 wicket ke nuqsaan par',\n",
              "  'india ke cricket wicket hai par 186 par par par par hai par feesad par hai'),\n",
              " ('dinon istanbul mein dastoori badshahat aur azaadi ke hawalay se behas mobahisa ho raha tha',\n",
              "  'uskay soudan ke ho tha ja se tha - mein tahiya liya hai - jehad tha tha   tha'),\n",
              " ('sab barri baat ki ke log islam dushmanon ke jin mein khaas kar shiaon hathon khail rahay hain',\n",
              "  'sab barri islam mein kami rahay hain toar ho ho hain daman ho rahay hain daman ho gi daman di'),\n",
              " ('lau dekh lau wohi kal aaj jin ke aa nah gaya',\n",
              "  'lau dekh commission nah gaya se tahiya gaya hain gaya hai ke gaya'),\n",
              " ('tamam ko tadaad ke sath nahi khra ke sath apnayen',\n",
              "  'tamam ko nahi ke paas hain ke liye mustamil jaien mustamil hain'),\n",
              " ('aap ke Muajzaat karamaat se hi log islam laya karte they',\n",
              "  'aap ke log mojood se tahiya rahay se kahani ki terhan hain they'),\n",
              " ('is se kya kisi gaaye ka pait bhar diya',\n",
              "  'is se bil den qatal diya ki tahiya ki aur siyasat'),\n",
              " ('husn ! hai jin ki sakhavat ki dhoom aalam mein',\n",
              "  'husn ! ki hindostan mein shuru se aalam se waqea ke aik'),\n",
              " ('ridaye dil pay nah ki talab sitara sahi',\n",
              "  'aeye dil kufar den par tahiya mein aamad ki tahiya'),\n",
              " ('is ki khwahish hai ke mein apna ne jari rakhon',\n",
              "  'is ki hai un tahiya rahay ki tahiya kyagyatha thisishypenhere qaida karna'),\n",
              " ('darya se ki shakhs jo piyasa palat gaya',\n",
              "  'darya se dekh _ hol mein tahiya y _ hol'),\n",
              " ('jabkay azaadi ki soorat hi nahi hai ki',\n",
              "  'dora azaadi nahi hai ki hai is hai hai ki hai'),\n",
              " ('ki sawal to Zubair Mirza bhai pouchye baghair reh nahi satke',\n",
              "  'ki sawal jee dagmaga ki tahiya satke par zaroorat ki tahiya kar hain'),\n",
              " ('aap ki Shamshad Lala ki baton mein aagaye mein to itni masoom hon',\n",
              "  'aap ki baton to baton liya zila y zila parh rahay ke hon ahal hon'),\n",
              " ('khudkushi ya hukmraanon ke hathon qatal ( aakhri hissa ) par tabsaray',\n",
              "  'khudkushi ya ki haasil par shafi ki haasil den par par hain par mabni'),\n",
              " ('tum kya gaye ke se gaye din bahhar ke',\n",
              "  'tum kya bahhar hain ke kal kal ke kal zila ke'),\n",
              " ('woh shakhs jis se se ke tanha bohat hue',\n",
              "  'woh shakhs se baat ki tahiya kyagyatha shuru karna par mustamil'),\n",
              " ('tumahray baad yahan mein bohat zaleel sun - hwa',\n",
              "  'buzurgon baad sun - ta _ hol jata se tahiya liya'),\n",
              " ('Dimashq mein fouj ke head quarter par khudkush hamlay',\n",
              "  'maghrib mein aalmi hamlay par hamlay hai ki taleem karli hamlay'),\n",
              " ('uskay baad saddar ronald rign ne usay mansookh kar diya',\n",
              "  'uskay baad ne matlab gaya ko tahiya mein tahiya kar ke hissa'),\n",
              " ('aap ki tafreeh taba ke tarjuma kya gaya',\n",
              "  'aap ki namona gaya ki tahiya mein tahiya mein tahiya'),\n",
              " ('rizwan bohat shore kar raha tha ke Pakistani rgbi',\n",
              "  'rizwan bohat hai is assembly hai is islami kamyaab se tahiya'),\n",
              " ('aakhri tadween : jummay boqt 9 : 41 shaam',\n",
              "  'aakhri tadween : ba tahiya mein day rahay mein tahiya chuki'),\n",
              " ('pahar rotay nahi hain janab saddar az aur chohadry',\n",
              "  'mah rotay out ki bolna haasil rahay par hai is hai'),\n",
              " ('haae woh bachi ki qismat haae woh zndan shaam',\n",
              "  'haae woh woh dosh bhi dosh rahay mein tahiya gaya hai'),\n",
              " ('Shahid Khan afridi - hunar to hai lekin insani nahi ki haalat mein',\n",
              "  'shahid khan hai lekin siyasat mein hain mein deeno shaamil se hai par shuru mein'),\n",
              " ('mujhe bohat pehlay ki baat yaad aayi ke kis terhan seeti bajanay par jahaaz pari bhi',\n",
              "  'mujhe bohat zayeqa bajanay bhi pheink aaya jahaaz to sadqy bhi - jahaaz bhi na karle - samaan'),\n",
              " ('zard karti jati hain sehraa mein palne ke sabab',\n",
              "  'sabz jati se hai ke par hain ki hai is hain'),\n",
              " ('yun samajh len ke mein lemoo lainay chali gayi bhi',\n",
              "  'yun samajh lainay mein award shuru karli zila zila zila zila zila'),\n",
              " ('ail o si par tijarat aur Dehli bas taluqaat',\n",
              "  '7 si aur aur qaumi tahiya kyagyatha ki tahiya shuru o'),\n",
              " ('ne khayaal mein jab bhook lagey kha lena chahiye raat ko sehri ka matlab laazmi 4 bujey nahi',\n",
              "  'ne khayaal kha ko bujey rahi ki girift nahi ki hai ki lagi ki lagi ! ki girift rahi hai'),\n",
              " ('Allah hum sab ko jehaad ki rooh se aashna kere',\n",
              "  'allah hum masjid dete hai ki tahiya karna thisishypenhere qaida karna misri'),\n",
              " ('amad Ali kaaf Afaq Raheem bay amad vsim 13 10 0 1',\n",
              "  'sami ali jhng e pehlay ki umeed par tahiya karna zila y yi tahiya'),\n",
              " ('ab ki acha sa bhai ya behan', 'ab ki bhi hay hay hain y _ hncha'),\n",
              " ('aur is chirr ki khabar jab ne waalid marhoom taq pohanchi to un se jo guftagu hui',\n",
              "  'aur is waalid bhi kere se baat se se tasaveer se se umeed se likhte se is hui se'),\n",
              " ('lekin mujhe aik punjabi mohawra yaad aa raha hai ke',\n",
              "  'lekin mujhe kon tha ke mutabiq hai ke mutabiq hai ke hai'),\n",
              " ('kal to hum ne salam kya kis ne jawab taq nahi diya',\n",
              "  'kal to kis agaya sakta mein tahiya nahi ki hai hai ki hai hai'),\n",
              " ('afsaraan zila ki taraqqi tanzuli ke baray mein report karne ka haq bhi usay ikhtiyar hota hai',\n",
              "  'se zila ke haq liya hai par hai par hota hai gaya par hai par hota hai par hai'),\n",
              " ('karzzzz khuwa ghnde ne kaha nawab ke bachay himmat hai to gaali day !',\n",
              "  'karzzzz khuwa ke baat day ga na ! zila day ! zila ki mili day !  !'),\n",
              " ('ki bhi lafz hon to ankhen bhiig jati hain',\n",
              "  'ki bhi to is tahiya rahay par hain ki hain hain'),\n",
              " ('hai karamat marey dil ki tre navak ki nahi',\n",
              "  'hai gole ki nahi ki ki nahi ki wajah ki hai'),\n",
              " ('lekin yeh tareeqa matrooq hochuka hai kyunkay raast ke qawaid naav ki nisbat bohat kam hain',\n",
              "  'lekin ki wajah aur is hain hain sab hain hain is ! zila bohat terhan hain hain !'),\n",
              " ('woh tohfa jo rasool Allah ( s ) ne shehzadi fatima ( seen ) ko diya',\n",
              "  'woh tohfa ( vote kiya zila zila kiya zila ko tahiya diya zila zila kiya zila kiya zila'),\n",
              " ('mohtaram bhai harf bah harf durust hai ya ke jumla bah jumla',\n",
              "  'mohtaram bhai he ke umeed ke suniye jari zila injaam zila injaam zila uf'),\n",
              " ('aap razi Allah anho rotay atay they aur farmatay .',\n",
              "  'aap razi they aur . zila zila sarsari jawab zila zila .'),\n",
              " ('sarkari mulazmeen par ghair mulki musalman ke sath shadi ki momanat ke qawaid',\n",
              "  'sarkari area ke liye tahiya se tahiya rahay ko hain hai waghera rahay ki tahiya')]"
            ]
          },
          "execution_count": 56,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# calculate the prediction\n",
        "preds_bucket_beam = predict_beam(test_buckets[current_index][0:100])\n",
        "preds_bucket_beam"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gtqom0c1xd7I",
        "outputId": "5296f052-09f6-4948-dbef-35d0b88590ed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "beam search\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
            "The hypothesis contains 0 counts of 3-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
            "The hypothesis contains 0 counts of 4-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
            "The hypothesis contains 0 counts of 2-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "BLEU SCORE OF BUCKET SIZE 20: 1.2043543072055763e-76\n",
            "ROUGE SCORE OF BUCKET SIZE 20: {'rouge1': 0.3108560672602514, 'rouge2': 0.0962900489216751, 'rougeL': 0.2890372374392871, 'rougeLsum': 0.28934142892869763}\n"
          ]
        }
      ],
      "source": [
        "# quantitaive analysis - bleu score of model, rouge score\n",
        "print('beam search')\n",
        "bleu_score = calculate_bleu_score(preds_bucket_beam)\n",
        "rouge = evaluate.load('rouge')\n",
        "expected = [pair[0] for pair in preds_bucket_beam]\n",
        "predicted = [pair[1] for pair in preds_bucket_beam]\n",
        "rouge_score = rouge.compute(predictions=predicted, references=expected)\n",
        "print(\"BLEU SCORE OF BUCKET SIZE 20:\", bleu_score)\n",
        "print(\"ROUGE SCORE OF BUCKET SIZE 20:\", rouge_score)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QlV0tSzL6yJw",
        "outputId": "010a4357-a7b9-4599-c166-1515f5da1dd8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0 test examples done, 100 left.\n",
            "all done!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[('jamaat yani imam ke ilawa kam se kam teen mard',\n",
              "  'jamaat yani imam ke ilawa kam se kam teen mard'),\n",
              " ('azal se le kar kaamil taq ki badolat ka ghulamana salam qubool kar !',\n",
              "  'azal se le kar kaamil taq ki badolat ka suhaag salam qubool kar !'),\n",
              " ('ke be abbu tha magar dost tha purana woh',\n",
              "  'ke be abbu tha magar dost tha akhbar woh waisa'),\n",
              " ('aur ab ki imandaar kisi kyun mein nahi kabhi ki cheezein khoobiyan sun - hwa karti theen',\n",
              "  'aur ab ki partners kisi kyun mein nahi kabhi ki cheezein larnay sun - hwa karti theen'),\n",
              " ('waisay guria se to kya aap khailtay hon ge bnta kar letay hain tarmeem kar ke : )',\n",
              "  'waisay guria se to kya aap khailtay hon ge ras kar letay hain gole kar ke : )'),\n",
              " ('ki sach hai naya zee hum sarka ray ka kha te hain',\n",
              "  'ki sach hai naya zee hum music ray ka kha te hain'),\n",
              " ('palat yahan se ! mra sheesha saaf nikla hai',\n",
              "  'palat yahan se ! mra sheesha saaf nikla hai'),\n",
              " ('woh khud saraab hai ouron ko aabb kya day ga',\n",
              "  'woh khud maanguu hai ouron ko ab kya day ga'),\n",
              " ('to tum kya sara din kamray mein pari rehti ho',\n",
              "  'to tum kya sara din kamray mein pari rehti ho'),\n",
              " ('jhoot ki bhi ki koi hoti hai -', 'jhoot ki bhi ki koi hoti hai -'),\n",
              " ('mein mehdi ne aik bunyaad daali jo dushmanon ke hamlay mein un ki panah gaah ban sakay',\n",
              "  'mein mehdi ne aik bunyaad daali jo dushmanon ke hamlay mein un ki panah gaah ban laga'),\n",
              " ('Zumra jaat : shairi , Farhat abbas Shah , muntakhib kalaam , nazam , nazmein',\n",
              "  'zumra jaat : shairi , farhat abbas shah , muntakhib kalaam , nazam , nazmein'),\n",
              " ('lekin baqi sawalaat kis qisam ke hon ge dara rahen aap to',\n",
              "  'lekin baqi sawalaat kis qisam ke hon ge dara rahen aap to'),\n",
              " ('kahani ka taana baana London ki ryil Azam haath ke gird bana gaya hai aur ko Sabiqa',\n",
              "  'kahani ka taana adakara london ki najaaiz azam pehlay ke gird bana gaya hai aur ko sabiqa'),\n",
              " ('halki barish hui aaj magar sardi qabil bardasht hai',\n",
              "  'halki barish hui aaj magar sardi qabil bardasht hai'),\n",
              " ('pehlay bhi marey zehan se daari hui bhi',\n",
              "  'pehlay bhi marey zehan se daari hui bhi free'),\n",
              " ('apna aik taaruf mehfhil par shareek kar dun ga',\n",
              "  'apna aik taaruf mehfhil par shareek kar dun ga free'),\n",
              " ('maffi chahta hon aap ko jawab dena bhool gaya',\n",
              "  'maffi chahta hon aap ko jawab dena bhool gaya'),\n",
              " ('is ki lambai kilometer mil se zayed hai',\n",
              "  'is ki lambai kilometer mil se zayed hai'),\n",
              " ('mehnat abad zila lateeni azbkstan ka aik jo sair darya soobah mein waqay hai',\n",
              "  'usmaan abad zila lateeni azbkstan ka aik jo sair darya soobah mein waqay hai'),\n",
              " ('abhi to mein mehfhil par kal aur aaj ki ziada parhte parhte idhar poanch gaya',\n",
              "  'abhi to mein mehfhil par kal aur aaj ki ziada parhte parhte idhar poanch gaya'),\n",
              " ('bohat nazar blaamtyaz bhai mein koshish karta hon',\n",
              "  'bohat nazar bhateejay bhai mein koshish karta hon'),\n",
              " ('azeem jheelon mein se payaab tareen jheel hai aur is ki ost geherai meter hai',\n",
              "  'azeem jheelon mein se mukhtari tareen jheel hai aur is ki ost geherai meter hai'),\n",
              " ('aik home tution se morad ke apne mamu .',\n",
              "  'aik home ke se morad ke apne mamu .'),\n",
              " ('Pakistan ke soobah Sindh ka naqsha zila jacob abad ko numaya kya gaya hai',\n",
              "  'pakistan ke soobah sindh ka naqsha zila khairpur abad ko numaya kya gaya hai'),\n",
              " ('yahan nai tazi abhi to yahi ke sardi bhaag gayi poori terhan',\n",
              "  'yahan nai tazi abhi to yahi ke sardi bhaag gayi poori terhan'),\n",
              " ('ishhq ke hain Muajzaat saltanat o fiqr o den',\n",
              "  'ishhq ke hain darbaan saltanat o qadir o den'),\n",
              " ('jabkay Iran ne inhen hazaar wapas bhi dhkila aur sazayen bhi den',\n",
              "  'jabkay iran ne inhen sangeet wapas bhi muntashir aur sazayen bhi shayad'),\n",
              " ('ya rab dua hai tujh se ki har dam Anees ki',\n",
              "  'ya rab dua hai tujh se ki har dam anees ki'),\n",
              " ('ab Mohammad sahib ke taaruf ki bhi ki zaroorat hai',\n",
              "  'ab mohammad sahib ke taaruf ki bhi ki zaroorat hai'),\n",
              " ('aur woh bhi poori ne dekh rahi hai is ke mutaliq kya irshad karna jab ge Fawad sahib',\n",
              "  'aur woh bhi poori ne dekh rahi hai is ke mutaliq kya irshad karna jab ge fawad sahib'),\n",
              " ('ne mamu se sun - hwa kya guzar raat ka',\n",
              "  'ne mamu se sun - hwa kya guzar raat ka free puhanche ka'),\n",
              " ('matti ki ki mourat hai ki sab tootay gi',\n",
              "  'matti ki ki loving hai ki sab tootay gi hmar'),\n",
              " ('kam az kam das saal se Pakistan ka shehri aur Pakistan mein sukoonat Pazeer ho',\n",
              "  'kam az kam das saal se pakistan ka shehri aur pakistan mein tainaat pazeer ho'),\n",
              " ('din mein martaba farz namazon ke liye muezzin yeh fareeza injaam deta hai',\n",
              "  'din mein martaba farz war ke liye haraval ki sarparasti injaam deta hai'),\n",
              " ('is film mein mustand scienci usool bhi bartay gay',\n",
              "  'is film mein hatmi scienci usool bhi guzaray gaye'),\n",
              " ('is ke se Safi ab technology ho chuka hai',\n",
              "  'is ke se tanqeedi ab technology ho chuka hai'),\n",
              " ('aur haan is mehfhil mein anay se pehlay dil insani sabhi frige mein bangal aati hon',\n",
              "  'aur haan is mehfhil mein anay se pehlay dil insani sabhi frige mein bangal aati hon'),\n",
              " ('chalees - se taq afraad ki halakat ka khadsha ae are why one world',\n",
              "  'chalees - se taq afraad ki halakat ka khadsha ae are why minute world'),\n",
              " ('kisi mein zar kisi mein sang ki hai phair qismat ka',\n",
              "  'kisi mein zar kisi mein sang ki hai phair qismat ka'),\n",
              " ('bohat nazar Ahmed bhai is hosla afzai ka',\n",
              "  'bohat nazar ahmed bhai is hosla afzai ka aitraaf'),\n",
              " ('kitaab azbkstan lateeni azbkstan ka aik insani abadkari jo Qushqa darya soobah mein waqay hai',\n",
              "  'kitaab azbkstan lateeni azbkstan ka aik insani abadkari jo qushqa darya soobah mein waqay hai'),\n",
              " ('nazar Shoiab bhai mein amal kar ke daikhta hon',\n",
              "  'nazar shoiab bhai mein amal kar ke daikhta hon'),\n",
              " ('maarka hai aaj . dekhieye woh kya kere hmm kya karen',\n",
              "  '05 hai aaj . dekhieye woh kya kere hmm kya karen'),\n",
              " ('mehfhil family awards 15 - fa - aal tareen rahay',\n",
              "  'mehfhil family awards 15 - tar tareen rahay ke khatmay'),\n",
              " ('roz kya din mein teen chaar baar bhi kabhi kabhi',\n",
              "  'roz kya din mein teen chaar baar bhi kabhi kabhi'),\n",
              " ('jo kho baithy hain ko raah phoolon ke hissaron mein',\n",
              "  'jo kho baithy hain ko raah lakhoon ke ba mein'),\n",
              " ('ab ke nah ki qasr nah ewaan bachay ga',\n",
              "  'ab ke nah ki bartanwi nah ewaan bachay ga'),\n",
              " ('soda kar is se dil ki tasalii ke wastay',\n",
              "  'soda karo is se dil ki tasalii ke wastay hmar'),\n",
              " ('jab ke ne totay ne jo quraa nikala hai is se mujhe ki ishara samajh aaya hai ke',\n",
              "  'jab ke ne totay ne jo cron nikala hai is se mujhe ki ishara samajh aaya hai ke'),\n",
              " ('Albata agar to ki is line ko cal karne mein bhi use',\n",
              "  'albata agar to ki is line ko cal karne mein bhi haliya'),\n",
              " ('apne shohar ke jawan saal teen ki maa bani aur kuch nah boli -',\n",
              "  'apne shohar ke jawan saal teen ki maa bani aur kuch nah boli -'),\n",
              " ('un ka intqaal hazrat Umar Farooq ke zamana khilafat mein sun - hwa',\n",
              "  'un ka intqaal hazrat umar farooq ke zamana khilafat mein sun - hwa'),\n",
              " ('mein ko ekloti behan ko miss kar raha hon !',\n",
              "  'mein ko 1991 behan ko miss kar raha hon !'),\n",
              " ('India ke 16 overs ke ekhtataam par 182 chay 2 wicket ke nuqsaan par',\n",
              "  'india ke 16 overs ke ekhtataam par 168 chay 2 wicket ke nuqsaan par'),\n",
              " ('dinon istanbul mein dastoori badshahat aur azaadi ke hawalay se behas mobahisa ho raha tha',\n",
              "  'uskay unatees mein francesi badshahat aur azaadi ke hawalay se behas mobahisa ho raha tha'),\n",
              " ('sab barri baat ki ke log islam dushmanon ke jin mein khaas kar shiaon hathon khail rahay hain',\n",
              "  'sab barri baat ki ke log islam dushmanon ke jin mein khaas kar shikni hathon khail rahay hain'),\n",
              " ('lau dekh lau wohi kal aaj jin ke aa nah gaya',\n",
              "  'lau dekh lau wohi kal aaj jin ke aa nah gaya'),\n",
              " ('tamam ko tadaad ke sath nahi khra ke sath apnayen',\n",
              "  'tamam ko tadaad ke sath nahi gary ke sath ohday'),\n",
              " ('aap ke Muajzaat karamaat se hi log islam laya karte they',\n",
              "  'aap ke naqaad kalmaat se hi log islam laya baghaawat they'),\n",
              " ('is se kya kisi gaaye ka pait bhar diya',\n",
              "  'is se kya kisi gaaye ka pait bhar diya'),\n",
              " ('husn ! hai jin ki sakhavat ki dhoom aalam mein',\n",
              "  'husn ! hai jin ki sakhavat ki khawari aalam mein'),\n",
              " ('ridaye dil pay nah ki talab sitara sahi',\n",
              "  'aeye dil pay nah ki talab mara - tar'),\n",
              " ('is ki khwahish hai ke mein apna ne jari rakhon',\n",
              "  'is ki khwahish hai ke mein apna ne jari rakhon'),\n",
              " ('darya se ki shakhs jo piyasa palat gaya',\n",
              "  'darya se ki shakhs jo piyasa palat gaya'),\n",
              " ('jabkay azaadi ki soorat hi nahi hai ki',\n",
              "  'dora azaadi ki soorat hi nahi hai ki free'),\n",
              " ('ki sawal to Zubair Mirza bhai pouchye baghair reh nahi satke',\n",
              "  'ki sawal to zubair mirza bhai pouchye baghair reh nahi len'),\n",
              " ('aap ki Shamshad Lala ki baton mein aagaye mein to itni masoom hon',\n",
              "  'aap ki shamshad lala ki baton mein aagaye mein to itni masoom hon'),\n",
              " ('khudkushi ya hukmraanon ke hathon qatal ( aakhri hissa ) par tabsaray',\n",
              "  'khudkushi ya hukmraanon ke hathon qatal ( aakhri hissa ) par tabsaray'),\n",
              " ('tum kya gaye ke se gaye din bahhar ke',\n",
              "  'tum kayi aa gaye ke se gaye din bahhar ke'),\n",
              " ('woh shakhs jis se se ke tanha bohat hue',\n",
              "  'woh shakhs jis se se ke tanha bohat hue'),\n",
              " ('tumahray baad yahan mein bohat zaleel sun - hwa',\n",
              "  'buzurgon baad yahan mein bohat sober sun - hwa'),\n",
              " ('Dimashq mein fouj ke head quarter par khudkush hamlay',\n",
              "  'maghrib mein fouj ke head quarter shehron london zair hamlay'),\n",
              " ('uskay baad saddar ronald rign ne usay mansookh kar diya',\n",
              "  'uskay baad saddar tabqaat'),\n",
              " ('aap ki tafreeh taba ke tarjuma kya gaya',\n",
              "  'aap ki zahanat taba ke tarjuma kya gaya'),\n",
              " ('rizwan bohat shore kar raha tha ke Pakistani rgbi',\n",
              "  'rizwan bohat shore kar raha tha ke pakistani rgbi'),\n",
              " ('aakhri tadween : jummay boqt 9 : 41 shaam',\n",
              "  'aakhri tadween : jummay boqt 9 : 41 shaam'),\n",
              " ('pahar rotay nahi hain janab saddar az aur chohadry',\n",
              "  'mah rotay nahi hain janab saddar : aur chohadry'),\n",
              " ('haae woh bachi ki qismat haae woh zndan shaam',\n",
              "  'haae woh bachi ki qismat haae woh bano shaam'),\n",
              " ('Shahid Khan afridi - hunar to hai lekin insani nahi ki haalat mein',\n",
              "  'shahid khan afridi - hunar to hai lekin insani nahi ki haalat mein'),\n",
              " ('mujhe bohat pehlay ki baat yaad aayi ke kis terhan seeti bajanay par jahaaz pari bhi',\n",
              "  'mujhe bohat pehlay ki baat yaad aayi ke kis terhan jehlum bajanay par jahaaz pari bhi'),\n",
              " ('zard karti jati hain sehraa mein palne ke sabab',\n",
              "  'zard karti jati hain karbalaa mein guftaar ke sabab'),\n",
              " ('yun samajh len ke mein lemoo lainay chali gayi bhi',\n",
              "  'yun samajh len ke mein black lainay chali gayi bhi free'),\n",
              " ('ail o si par tijarat aur Dehli bas taluqaat',\n",
              "  'ail o si par tijarat aur dehli bas baal'),\n",
              " ('ne khayaal mein jab bhook lagey kha lena chahiye raat ko sehri ka matlab laazmi 4 bujey nahi',\n",
              "  'ne khayaal mein jab bhook lagey kha lena chahiye raat ko sehri ka matlab laazmi 4 bujey nahi'),\n",
              " ('Allah hum sab ko jehaad ki rooh se aashna kere',\n",
              "  'allah hum sab ko jehaad ki rooh se aashna kere'),\n",
              " ('amad Ali kaaf Afaq Raheem bay amad vsim 13 10 0 1',\n",
              "  'sami ali kaaf mustafa raheem bay sami vsim 13 10 15 0 1'),\n",
              " ('ab ki acha sa bhai ya behan', 'ab ki acha sa bhai ya behan zila'),\n",
              " ('aur is chirr ki khabar jab ne waalid marhoom taq pohanchi to un se jo guftagu hui',\n",
              "  'aur is stor ki khabar jab ne waalid marhoom taq pohanchi to un se jo guftagu hui'),\n",
              " ('lekin mujhe aik punjabi mohawra yaad aa raha hai ke',\n",
              "  'lekin mujhe aik punjabi mohawra yaad aa raha hai ke'),\n",
              " ('kal to hum ne salam kya kis ne jawab taq nahi diya',\n",
              "  'kal to hum ne salam kya kis ne jawab taq nahi diya'),\n",
              " ('afsaraan zila ki taraqqi tanzuli ke baray mein report karne ka haq bhi usay ikhtiyar hota hai',\n",
              "  'se zila ki taraqqi chyontyon ke baray mein report karne ka haq bhi usay ikhtiyar hota hai'),\n",
              " ('karzzzz khuwa ghnde ne kaha nawab ke bachay himmat hai to gaali day !',\n",
              "  'karzzzz khuwa dilwanay ne kaha nawab ke bachay himmat hai to gaali day !'),\n",
              " ('ki bhi lafz hon to ankhen bhiig jati hain',\n",
              "  'ki bhi lafz hon to ankhen bhiig jati hain'),\n",
              " ('hai karamat marey dil ki tre navak ki nahi',\n",
              "  'hai mawra marey dil ki tre suhaag ki nahi'),\n",
              " ('lekin yeh tareeqa matrooq hochuka hai kyunkay raast ke qawaid naav ki nisbat bohat kam hain',\n",
              "  'lekin ki tareeqa tasmia hochuka hai kyunkay fouj ke lutne quied ayyaam ki nisbat bohat kam hain'),\n",
              " ('woh tohfa jo rasool Allah ( s ) ne shehzadi fatima ( seen ) ko diya',\n",
              "  'woh tohfa jo rasool allah ( s ) ne guzaray fatima ( ( )'),\n",
              " ('mohtaram bhai harf bah harf durust hai ya ke jumla bah jumla',\n",
              "  'mohtaram bhai harf bah harf durust hai ya ke jumla bah jumla'),\n",
              " ('aap razi Allah anho rotay atay they aur farmatay .',\n",
              "  'aap razi allah anho rotay jatay they aur farmatay .'),\n",
              " ('sarkari mulazmeen par ghair mulki musalman ke sath shadi ki momanat ke qawaid',\n",
              "  'sarkari area par ghair mulki musalman ke sath shadi ki momanat ke mutanazia')]"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# calculate the prediction\n",
        "preds_bucket_greedy = predict_greedy(test_buckets[current_index][0:100])\n",
        "preds_bucket_greedy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 234,
          "referenced_widgets": [
            "8300d5541b1f4a2d9879a4ea6da5390c",
            "437b4a9d5e954f008a2361d3ebc4e816",
            "9fff09d6f4e045df9deb67ce9959fd9d",
            "66e6beeaefe14a80a8d10e63d718fafd",
            "a077fb524ded413cbe779c0136381560",
            "6818f9a3069846b7bfe1ba5c8f0e4f65",
            "1d1a686d2e3a4a6da822c164ce1d38c7",
            "f28233ea0f8b4d099010c8a4bf02aec3",
            "90a15fe6ae7b4b9cbdc1e82f7fc18d3d",
            "c3d9fca6d998426eaf798591b5ce947d",
            "60d7788b7f6b41c8b23117f3cc9696ff"
          ]
        },
        "id": "WwG2qsPJdBmL",
        "outputId": "ef4b338e-ef90-491a-e8de-55204a648c5c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "greedy search\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
            "The hypothesis contains 0 counts of 4-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8300d5541b1f4a2d9879a4ea6da5390c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading builder script:   0%|          | 0.00/6.27k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "BLEU SCORE OF BUCKET SIZE 20: 74.00313046096531\n",
            "ROUGE SCORE OF BUCKET SIZE 20: {'rouge1': 0.9008228826857693, 'rouge2': 0.82553781430192, 'rougeL': 0.9005644124322528, 'rougeLsum': 0.9011126384580325}\n"
          ]
        }
      ],
      "source": [
        "# quantitaive analysis - bleu score of model, rouge score\n",
        "print('greedy search')\n",
        "bleu_score = calculate_bleu_score(preds_bucket_greedy)\n",
        "rouge = evaluate.load('rouge')\n",
        "expected = [pair[0] for pair in preds_bucket_greedy]\n",
        "predicted = [pair[1] for pair in preds_bucket_greedy]\n",
        "rouge_score = rouge.compute(predictions=predicted, references=expected)\n",
        "print(\"BLEU SCORE OF BUCKET SIZE 20:\", bleu_score)\n",
        "print(\"ROUGE SCORE OF BUCKET SIZE 20:\", rouge_score)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4WbjheUZ2lCF",
        "outputId": "28cbbb07-268a-49d2-8171-1d875cdf41c7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Urdu Sentence: اس سا ے سے صفی اب محروم ہو چکا ہے\n",
            "Actual Roman Urdu Sentence: is ke se Safi ab technology ho chuka hai\n",
            "Predicted Roman Urdu Sentence: is ke se tanqeedi ab technology ho chuka hai\n",
            "\n",
            "Urdu Sentence: کل تو ہم نے سلام کیا کس نے جواب تک نہیں دیا\n",
            "Actual Roman Urdu Sentence: kal to hum ne salam kya kis ne jawab taq nahi diya\n",
            "Predicted Roman Urdu Sentence: kal to hum ne salam kya kis ne jawab taq nahi diya\n",
            "\n",
            "Urdu Sentence: دن میں مرتبہ فرض نمازوں کے ل ے موذن یہ فریضہ انجام دیتا ہے\n",
            "Actual Roman Urdu Sentence: din mein martaba farz namazon ke liye muezzin yeh fareeza injaam deta hai\n",
            "Predicted Roman Urdu Sentence: din mein martaba farz war ke liye haraval ki sarparasti injaam deta hai\n",
            "\n",
            "Urdu Sentence: ایل او سی پر تجارت اور بس سروس بحال\n",
            "Actual Roman Urdu Sentence: ail o si par tijarat aur Dehli bas taluqaat\n",
            "Predicted Roman Urdu Sentence: ail o si par tijarat aur dehli bas baal\n",
            "\n",
            "Urdu Sentence: اور ہاں اس محفل میں انے سے پہلے دل دماغ سبھی فرج میں رکھ اتی ہوں\n",
            "Actual Roman Urdu Sentence: aur haan is mehfhil mein anay se pehlay dil insani sabhi frige mein bangal aati hon\n",
            "Predicted Roman Urdu Sentence: aur haan is mehfhil mein anay se pehlay dil insani sabhi frige mein bangal aati hon\n",
            "\n",
            "Urdu Sentence: اب کے نہ کو ی قصر نہ ایوان بچے گا\n",
            "Actual Roman Urdu Sentence: ab ke nah ki qasr nah ewaan bachay ga\n",
            "Predicted Roman Urdu Sentence: ab ke nah ki bartanwi nah ewaan bachay ga\n",
            "\n",
            "Urdu Sentence: کہ بے وفا تھا مگر دوست تھا پرانا وہ\n",
            "Actual Roman Urdu Sentence: ke be abbu tha magar dost tha purana woh\n",
            "Predicted Roman Urdu Sentence: ke be abbu tha magar dost tha akhbar woh waisa\n",
            "\n",
            "Urdu Sentence: اس کی لمبا ی کلومیٹر میل سے زا د ہے\n",
            "Actual Roman Urdu Sentence: is ki lambai kilometer mil se zayed hai\n",
            "Predicted Roman Urdu Sentence: is ki lambai kilometer mil se zayed hai\n",
            "\n",
            "Urdu Sentence: ابھی تو میں محفل پر کل اور اج کی پوسٹس پڑھتے پڑھتے ادھر پہنچ گیا\n",
            "Actual Roman Urdu Sentence: abhi to mein mehfhil par kal aur aaj ki ziada parhte parhte idhar poanch gaya\n",
            "Predicted Roman Urdu Sentence: abhi to mein mehfhil par kal aur aaj ki ziada parhte parhte idhar poanch gaya\n",
            "\n",
            "Urdu Sentence: ردا ے دل پہ نہ کو ی طلب ستارہ سہی\n",
            "Actual Roman Urdu Sentence: ridaye dil pay nah ki talab sitara sahi\n",
            "Predicted Roman Urdu Sentence: aeye dil pay nah ki talab mara - tar\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# qualitative analysis - lets see a few example sentences and their transliterations\n",
        "# since greedy gave better performance on quant. metrics, we are just showing the sentences using greedy approach.\n",
        "for i in range(10):\n",
        "  inx = random.randint(0, len(preds_bucket_greedy))\n",
        "  r, u = test_buckets[current_index][inx]\n",
        "  print('Urdu Sentence:', u.replace('<start>', '').replace('<end>', '').strip())\n",
        "  print('Actual Roman Urdu Sentence:', r.replace('<start>', '').replace('<end>', '').strip())\n",
        "  orig, pred = preds_bucket_greedy[inx]\n",
        "  print('Predicted Roman Urdu Sentence:', pred.replace('<start>', '').replace('<end>', '').strip())\n",
        "  print()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "1d1a686d2e3a4a6da822c164ce1d38c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "437b4a9d5e954f008a2361d3ebc4e816": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6818f9a3069846b7bfe1ba5c8f0e4f65",
            "placeholder": "​",
            "style": "IPY_MODEL_1d1a686d2e3a4a6da822c164ce1d38c7",
            "value": "Downloading builder script: 100%"
          }
        },
        "60d7788b7f6b41c8b23117f3cc9696ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "66e6beeaefe14a80a8d10e63d718fafd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c3d9fca6d998426eaf798591b5ce947d",
            "placeholder": "​",
            "style": "IPY_MODEL_60d7788b7f6b41c8b23117f3cc9696ff",
            "value": " 6.27k/6.27k [00:00&lt;00:00, 336kB/s]"
          }
        },
        "6818f9a3069846b7bfe1ba5c8f0e4f65": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8300d5541b1f4a2d9879a4ea6da5390c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_437b4a9d5e954f008a2361d3ebc4e816",
              "IPY_MODEL_9fff09d6f4e045df9deb67ce9959fd9d",
              "IPY_MODEL_66e6beeaefe14a80a8d10e63d718fafd"
            ],
            "layout": "IPY_MODEL_a077fb524ded413cbe779c0136381560"
          }
        },
        "90a15fe6ae7b4b9cbdc1e82f7fc18d3d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9fff09d6f4e045df9deb67ce9959fd9d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f28233ea0f8b4d099010c8a4bf02aec3",
            "max": 6270,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_90a15fe6ae7b4b9cbdc1e82f7fc18d3d",
            "value": 6270
          }
        },
        "a077fb524ded413cbe779c0136381560": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c3d9fca6d998426eaf798591b5ce947d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f28233ea0f8b4d099010c8a4bf02aec3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
